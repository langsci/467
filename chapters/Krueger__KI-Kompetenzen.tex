\documentclass[output=paper]{langscibook}
\ChapterDOI{10.5281/zenodo.17523062}
\author{Ralph Krüger\orcid{}\affiliation{TH Köln}}
\title{Künstliche Intelligenz in Translation und Fachkommunikation: Skizze eines Kompetenzrahmens}
\abstract{In diesem Kapitel wird ein KI-Kompetenzrahmen für Translation und Fachkommunikation skizziert, dessen Notwendigkeit sich aus den jüngsten Entwicklungen im Bereich der sprachbezogenen Künstlichen Intelligenz (KI) – insbesondere im Bereich der Large Language Models (LLMs) – ergibt. Zunächst wird kurz das Verhältnis von neuronaler maschineller Übersetzung (NMÜ) und LLMs diskutiert und im Anschluss das Spektrum translatorischer/fachkommunikativer Arbeitsgänge dargestellt, die insbesondere durch Mehrzweck-KI-Technologien wie LLMs (teil-)automatisiert werden können. Daran an schließt eine Diskussion der angesichts dieser Automatisierung von Translation und Fachkommunikation erforderlichen Digitalkompetenzen, insbesondere in den Bereichen maschinelle Übersetzung, Daten und Künstliche Intelligenz im Allgemeinen. Die entsprechenden Kompetenzbündel MT Literacy, Data Literacy und AI Literacy sowie deren Schnittstellen werden diskutiert und es wird ein daraus abgeleiteter KI-Kompetenzrahmen für Translation und Fachkommunikation skizziert. Im Anschluss werden die einzelnen Dimensionen dieses Kompetenzrahmens im Detail dargestellt und punktuell auf mögliche praktische Anwendungskontexte bezogen.}
\IfFileExists{../localcommands.tex}{
  \addbibresource{../localbibliography.bib}
  \input{../localpackages}
  \input{../localcommands} 
  \input{../localhyphenation} 
  \togglepaper[1]%%chapternumber
}{}

\begin{document}
\maketitle 
\shorttitlerunninghead{Ein KI-Kompetenzrahmen für Translation und Fachkommunikation}%%use this for an abridged title in the page headers


\section{Automatisierung und Digitalkompetenzen  in Translation und Fachkommunikation}
\label{krueger:sec:automatisierung}

Seitdem die Autoren des in der Translationswissenschaft zu einer gewissen Berühmtheit gelangten ALPAC-Reports \citep{automatic_language_processing_advisory_committee_languages_1966} vor fast 60 Jahren dem damaligen Leistungspotenzial der maschinellen Übersetzung (MÜ) ein ungenügendes Zeugnis ausstellten und die Verlagerung künftiger Forschungsbemühungen weg von der \textit{maschinellen} Übersetzung und hin zur \textit{rechnergestützten} Übersetzung empfahlen\footnote{„[T]here is no immediate or predictable prospect of useful machine translation. […] Machine-aided translation may be an important avenue towards better, quicker, and cheaper translation.” \citet[32]{automatic_language_processing_advisory_committee_languages_1966}.}, ist der Automatisierungsgrad des Übersetzungsprozesses sukzessive erhöht worden (vgl. den historischen Überblick in \cite{chan_development_2023} sowie in diesem Buch in Kapitel 1). Die im ALPAC-Report noch geschmähte MÜ hat spätestens mit dem Siegeszug des Machine-Learning-Paradigmas in der Forschung zur Künstlichen Intelligenz Anfang/Mitte der 2010er Jahre in ihrer Ausprägung als neuronale maschinelle Übersetzung ein beachtliches Leistungsniveau erreicht und kann heute sicherlich mit gutem Recht als translatorische Leittechnologie bezeichnet werden. Ein Meilenstein in der NMÜ- und der breiteren KI-Forschung war die Entwicklung des Transformers \citep{vaswani_attention_2017}, einer speziellen Ausprägung eines neuronalen Netzes, die besonders gut für die Verarbeitung natürlicher Sprache geeignet ist. Der ursprünglich für die MÜ konzipierte Transformer bildete später auch die Architekturgrundlage für sogenannte Large Language Models (LLMs) wie beispielsweise die GPT-Modelle von OpenAI, die Claude-Modelle von Cohere oder die Gemini-Modelle von Google. LLMs verfügen über die Eigenschaft des „In-Context Learning“ \citep[3]{brown_language_2020}, d. h., sie können durch natürlichsprachliches Prompting mit zahlreichen sprachbezogenen Aufgaben über die maschinelle Übersetzung hinaus betraut werden. Dementsprechend werden diese Modelle – u. a. in der aktuellen KI-Gesetzgebung der Europäischen Union – auch als „general-purpose AI technologies“ \citep[1]{madiega_generative_2023}, zu Deutsch ‚Mehrzweck-KI-Technologien‘, bezeichnet. Bei aktuellen Modellen wie beispielsweise GPT-4o \citep[vgl.][]{openai_hello_2024} handelt es sich außerdem um \textit{multimodale LLMs} \citep{zhang_mm-llms_2024}, die neben Schriftsprache auch andere Modalitäten wie Bilder, Videos und Audiosignale verarbeiten können. Diese Funktionsvielfalt multimodaler LLMs hat zur Folge, dass eine große Zahl von Arbeitsgängen nicht nur im Übersetzen, sondern auch im verwandten translatorischen Arbeitsfeld des Dolmetschens und in der dem Übersetzen ebenfalls wesensverwandten technischen Redaktion (im Folgenden: Translation und Fachkommunikation) durch diese Modelle (teil-)automatisiert bzw. unterstützt werden können. Dies ist in Abbildung 1 exemplarisch dargestellt.

\begin{figure}
\includegraphics[width=\textwidth]{figures/Krueger__Abb-1_Einsatzpotenziale-LLM.png}
\caption{Spektrum der durch LLMs potenziell \mbox{(teil-)}automatisierbaren Arbeitsgänge in Translation und Fachkommunikation (CC BY-SA 4.0)}
\end{figure}

In der Übersetzung können LLMs beispielsweise über die \glqq{}klassische\grqq{} maschinelle Übersetzung hinaus mit Aufgaben im Bereich der Qualitätsbewertung, der Qualitätsoptimierung (Pre-/Post-Editing, maschinelles Lektorat), der Informationsrecherche/Terminologiearbeit oder womöglich auch im Bereich des Projektmanagements betraut werden. LLMs, die zur Verarbeitung mündlicher Sprache in der Lage sind, können außerdem potenziell zum maschinellen Dolmetschen eingesetzt werden, und die Fähigkeit generativer Sprachmodelle zur autonomen Textproduktion oder auch zur einsprachigen Texttransformation (z. B. Entwicklerdokumentation → Bedienungsanleitung) könnte in der technischen Redaktion genutzt werden.\footnote{Auch im Dolmetschen und der technischen Redaktion ist selbstverständlich eine LLM-Unterstützung in den Bereichen Informationsrecherche/Terminologiearbeit, Qualitätsbewertung und (womöglich eher in der technischen Redaktion als im Dolmetschen) Qualitätsoptimierung möglich.} Da moderne LLMs nicht nur natürliche Sprachen, sondern i.~d.~R. auch Formalsprachen (z. B. Programmiersprachen wie Python, Auszeichnungssprachen wie XML oder Textmuster wie reguläre Ausdrücke) beherrschen, können sie auch in diesem Bereich eine Unterstützung bieten, wenn beispielsweise im Übersetzen oder der technischen Redaktion reguläre Ausdrücke zur Identifizierung und ggf. Manipulation bestimmter Zeichenketten (E-Mail-Adressen, Telefonnummern, Maßeinheiten usw.) geschrieben werden müssen. 

Eine solche (Teil-)Automatisierung translatorischer/fachkommunikativer Arbeitsgänge kann aus einer Kompetenzperspektive unterschiedlich bewertet werden. So nimmt \citet[51]{sandrini_its_2022} in seinem \textit{Translatoren-Obsoleszenz-Zyklus} Teilaufgaben des Übersetzungsprozesses in den Blick, die bei einer Erhöhung des Automatisierungsgrades von einem Computer übernommen werden können. Aufseiten menschlicher Übersetzer:innen werden diese Aufgaben damit obsolet, was womöglich entsprechende Kompetenzverluste mit sich bringt (so entfällt z. B. durch den Einsatz von Terminologiedatenbanken die Notwendigkeit der Memorisierung von Fachtermini und durch den Einsatz von MÜ-Systemen die Notwendigkeit der Anfertigung einer Rohübersetzung, vgl. ebd.). In einem ähnlichen Zusammenhang sprechen \citet[9]{schatsky_redesigning_2015} von möglichen Kompetenzverlusten („Deskilling“), die mit einem übermäßigen Technologieeinsatz verbunden sein können. \citet[278]{olohan_technology_2017} weist dagegen – wieder mit Blick auf das Übersetzen – darauf hin, dass mit einer Erhöhung des translatorischen Automatisierungsgrades auch ein „upskilling of translators“ einhergehen kann. Denn schließlich resultiert ein höherer Automatisierungsgrad häufig in einer höheren Komplexität der jeweiligen (teil-)automatisierten Prozesse, woraus wiederum neue prozessanalytische, prozessorganisatorische und technologische Kompetenzanforderungen erwachsen \citep[vgl. hierzu auch][]{kruger_technologieinduzierte_2018}. Dieser Gedanke eines technologieinduzierten Upskillings soll in diesem Beitrag aufgegriffen und mit Blick auf die zuvor besprochenen LLMs weiter ausgearbeitet werden. Es könnte in diesem Zusammenhang argumentiert werden, dass diese Mehrzweck-KI-Technologien nur dann in adäquater Weise in Praxisworkflows integriert werden können und ihr Potenzial zur (Teil-)Automatisierung translatorischer/fachkommunikativer Arbeitsgänge nur dann voll ausgeschöpft werden kann, wenn die Nutzer:innen dieser Modelle über entsprechende Kompetenzen entlang mehrerer Dimensionen verfügen, wie dies in dem in Abschnitt \ref{krueger:sec:skizze} skizzierten Kompetenzrahmen abgebildet werden soll. Empirisch gestützt wird diese Annahme beispielsweise durch eine gemeinsame Umfrage von Slator und der Association of Language Companies aus dem Jahr 2023, bei der 34~\% der befragten Sprachdienstleister KI und Big Data als die wichtigsten Kompetenzfelder der kommenden Jahre nannten (vgl. \cite{edwards_customer_2023}).

\section{MT Literacy, Data Literacy und AI Literacy \\
und ihre Schnittstellen}
\label{krueger:sec:mtliteracy}

Aus dem Blickwinkel \textit{Upskilling als Reaktion auf Automatisierung} sind in der Translationswissenschaft in den letzten Jahren insbesondere drei Bündel von Digitalkompetenzen diskutiert worden, die mit Blick auf das Erkenntnisinteresse des aktuellen Beitrags von besonderer Relevanz sind. Diese drei Kompetenzbündel und ihre Schnittstellen sind in Abbildung \ref{krueger:fig:mtliteracy} dargestellt.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/[neu] Krueger__Abb-2_MT-Literacy.pdf}
\caption{\label{krueger:fig:mtliteracy}MT Literacy, Data Literacy und AI Literacy sowie deren Schnittstellen (CC BY-SA 4.0)}
\end{figure}

In Zusammenhang mit der zunehmenden Relevanz der maschinellen Übersetzung sowohl in der Sprachindustrie als auch in der breiteren Gesellschaft haben \citet{bowker_towards_2019} den Begriff der \textit{Machine Translation Literacy} geprägt (siehe hierzu auch Kapitel \ref{tieber:title}), der von \citet[146]{ehrensberger-dow_new_2023} definiert wird als „knowing how MT works, how it can be useful in a particular context, and what the implications are of using MT for specific communicative needs“. Mit Blick auf das professionelle Fachübersetzen habe ich darauf aufbauend den Begriff der \textit{Professional MT Literacy} vorgeschlagen. Dieser beschreibt “the full range of MT-related competences professional translators (and other language professionals) may require in order to participate successfully in the various phases of the MT-assisted professional translation process” \citep[249]{kruger_outline_2022}. Der zweite im aktuellen Zusammenhang relevante Begriff ist der der \textit{Data Literacy}, definiert als „the ability to collect, manage, evaluate, and apply data, in a critical manner“ (\cite[11]{ridsdale_strategies_2015}). Die Schnittstelle zwischen MT und Data Literacy bildet die korpusbasierte maschinelle Übersetzung, insbesondere in ihrer Ausprägung als NMÜ, die nicht, wie frühe regelbasierte MÜ-Systeme, mit explizitem linguistischen Wissen operiert, sondern mit umfangreichen Übersetzungskorpora trainiert wird und aus ihren Trainingsdaten eigene Repräsentationen und Übersetzungsmuster erlernt (Representation Learning im Rahmen des Machine-Learning-Paradigmas). Die Schnittstelle zwischen MT Literacy und Data Literacy wurde ausführlich in dem Projekt \textit{DataLit\textsuperscript{MT}} bearbeitet, in dessen Rahmen Lerninhalte zur Vermittlung von Datenkompetenzen im Kontext der NMÜ entwickelt wurden \citep[vgl.][]{kruger_artificial_2023, hackenbuchner_datalitmt_2023}.\footnote{Projektergebnisse von DataLit\textsuperscript{MT}: \url{https://itmk.github.io/The-DataLitMT-Project/} (24.04.2024)} Das dritte im aktuellen Kontext relevante Kompetenzbündel firmiert unter dem Namen \textit{Artificial Intelligence Literacy} und wird von \citet[1]{long_what_2020} definiert als „a set of competencies that enables individuals to critically evaluate AI technologies; communicate and collaborate effectively with AI; and use AI as a tool online, at home, and in the workplace.“ Angesichts der Ubiquität leistungsstarker KI-Technologien in modernen Gesellschaften (KI als \glqq{}Everyware\grqq{}, \cite{greenfield_everyware_2006}) sind zunehmend Stimmen zu vernehmen, laut denen AI Literacy neben traditionellen Lese-, Schreib- und Rechenkompetenzen sowie allgemeinen Digitalkompetenzen zu den wichtigsten Kompetenzbündeln des 21. Jahrhunderts gehört \citep[vgl.][9]{ng_conceptualizing_2021}. Die Schnittstelle zwischen AI Literacy und Data Literacy bildet das bereits angesprochene Machine-Learning-Paradigma innerhalb der übergeordneten KI-Forschung, in dessen Rahmen neuronale Netze mit umfangreichen Trainingsdatenbeständen trainiert werden und aus diesen Trainingsdaten Repräsentationen und Muster erlernen (vgl. die Erläuterungen zur korpusbasierten MÜ als spezifischer Ausprägung eines Machine-Learning-Systems). Diese untrennbare Verflechtung von Algorithmen und Daten in modernen KI-Technologien hat damit auch eine entsprechende Verflechtung von Data Literacy und AI Literacy zur Folge. Die Schnittstelle zwischen AI Literacy und MT Literacy bilden die bereits besprochenen LLMs, die aus der NMÜ-Forschung hervorgegangen sind und auf einem ähnlichen Funktionsprinzip wie die NMÜ beruhen (mit dem Transformer als gemeinsamer Architekturgrundlage). Angesichts dieser Genealogie kann bei der theoretischen Ausarbeitung und didaktischen Operationalisierung einer translatorischen/fachkommunikativen AI Literacy auf Vorarbeiten zu einer Professional MT Literacy und einer MÜ-spezifischen Data Literacy zurückgegriffen werden (vgl. die Diskussion im nachstehenden Abschnitt).

\section{Skizze eines KI-Kompetenzrahmens für Translation und Fachkommunikation}
\label{krueger:sec:skizze}

Der nachstehend skizzierte KI-Kompetenzrahmen für Translation und Fachkommunikation basiert in Teilen auf drei bestehenden Kompetenzrahmen: 1) dem im Kontext von DataLit\textsuperscript{MT} entwickelten \textit{Professional MT Literacy Framework} \citep[vgl.][]{kruger_outline_2022} , 2) dem \textit{DataLit\textsuperscript{MT}} \textit{Framework} (einem in demselben Projekt entwickelten MÜ-spezifischen Data Literacy Framework, vgl. ebd.) und 3) dem \textit{AI Literacy Framework} von \citet{long_what_2020}. Im Professional MT Literacy Framework werden die im professionellen Fachübersetzen erforderlichen MÜ-Kompetenzen auf fünf Dimensionen verteilt (\textit{technical MT literacy}, \textit{linguistic MT literacy}, \textit{economic MT literacy}, \textit{societal MT literacy} und \textit{cognitive MT literacy}), die jeweils in weitere Teildimensionen aufgefächert sind. Das DataLit\textsuperscript{MT} Framework modelliert den Datenlebenszyklus innerhalb eines MÜ-Projektes und ist in die fünf Dimensionen \textit{Data context}, \textit{Data planning}, \textit{Data collection/production}, \textit{Data evaluation} und \textit{Data use} unterteilt (jeweils wieder in weitere Teildimensionen aufgefächert). Bei dem AI Literacy Framework von \citet{long_what_2020} handelt es sich um einen generischen, sprich nicht domänenspezifischen, Kompetenzrahmen, der entlang der fünf Fragen \textit{What is AI?}, \textit{What can AI do?}, \textit{How does AI work?}, \textit{How should AI be used?} und \textit{How do people perceive AI?} strukturiert ist.\footnote{Das Professional MT Literacy Framework und das DataLit\textsuperscript{MT} Framework sowie die Schnittstelle zwischen diesen beiden Kompetenzrahmen werden in \citet{kruger_outline_2022} im Detail beschrieben. Das AI Literacy Framework von \citet{long_what_2020} sowie die Schnittstelle zwischen diesem und den beiden vorgenannten Kompetenzrahmen werden in \citet{kruger_artificial_2023} eingehend besprochen.} Der auf Grundlage dieser konzeptuellen Vorläufer entwickelte KI-Kompetenzrahmen für Translation und Fachkommunikation in seiner Entwurfsfassung ist in Abbildung \ref{fig:krueger-3} dargestellt.

  
\begin{figure}
\includegraphics[width=\textwidth]{figures/[neu] Krueger__Abb-3_Kompetenzrahmen.pdf}
\caption{Skizze eines KI-Kompetenzrahmens für Translation und Fachkommunikation (CC BY-SA 4.0)}
\label{fig:krueger-3}
\end{figure}

Im Folgenden werden die fünf Dimensionen des Kompetenzrahmens genauer besprochen und dabei einzelne Teilkompetenzen exemplarisch fokussiert.

\subsection{Technische Grundlagen}
\label{krueger:subsec:tech_grundlagen}

Die erste Dimension des skizzierten Kompetenzrahmens befasst sich mit den technischen Grundlagen moderner KI-Verfahren. Hierunter fallen grundlegende Kenntnisse der Funktionsweise aktueller KI-Technologien sowie des Trainings dieser Technologien, ein Bewusstsein für die Verflechtung von KI-Modellen und deren Trainingsdaten (wodurch gleichzeitig die Anschlussfähigkeit des Kompetenzrahmens an einschlägige Datenkompetenzrahmen hergestellt wird) sowie Kenntnisse der Funktionsweise und der Notwendigkeit der Kennzeichnung KI-generierter Inhalte.\footnote{Eine solche Kennzeichnung ist insbesondere im Kontext des modernen KI-Technologien innewohnenden Manipulationspotenzials zu sehen, das in dem skizzierten Kompetenzrahmen unter \textit{Ethische/gesellschaftliche Aspekte} (vgl. Abschnitt \ref{krueger:subsec:ethische}) aufgeführt ist.} In der Translationswissenschaft werden Forderungen nach technischen Grundkenntnissen im Bereich moderner Translationstechnologien (speziell der NMÜ) häufig mit dem Empowerment von Übersetzer:innen begründet, das mitunter eingeschränkt ist, wenn diese Übersetzer:innen die Funktionsweise solcher Technologien aufgrund von deren \glqq{}Blackbox\grqq{}-Charakter nicht nachvollziehen können.\footnote{Vgl. hierzu \citep[438]{kenny_machine_2019}: „Increased opacity […] is a particular cause for concern for humans required to work with contemporary MT systems because it can limit their ability to intervene in translation workflows, thus undermining agendas of translator empowerment […].“} Dieser Befund gilt sicherlich auch für Mehrzweck-KI-Technologien wie LLMs sowie für die verwandten Berufsbilder des Dolmetschens und der technischen Redaktion. An dieser Stelle wird allerdings auch direkt ersichtlich, dass der hier skizzierte Kompetenzrahmen in seiner aktuellen Form lediglich eine Momentaufnahme der sehr dynamischen KI-Landschaft darstellt und möglicherweise schon bald an neue Entwicklungen in diesem Bereich angepasst werden muss. So wird hier beispielsweise der Transformer als aktuelle State-of-the-Art-Architektur im KI-Bereich aufgeführt. Allerdings werden derzeit auch alternative Modellarchitekturen (z. B. sog. \glqq{}State Space Models\grqq{} wie \textit{Mamba}, vgl. \cite{gu_mamba_2023}) erforscht, die dem Transformer in Zukunft Konkurrenz machen oder diesen womöglich auch als Leitarchitektur ersetzen könnten.

\subsection{Domänenspezifische Performanz}
\label{krueger:subsec:domaenenspezifische}

Im Kontext der domänenspezifischen Performanz geht es zunächst einmal um ein Bewusstsein für den Funktionsumfang von modernen KI-Technologien (vgl. die Diskussion in Abschnitt \ref{krueger:sec:automatisierung}), was auch ein Verständnis der verfügbaren Ein- und Ausgabemodalitäten dieser Technologien umfasst. Aufbauend darauf können dann das aufgabenspezifische Leistungsniveau dieser Technologien und – damit zusammenhängend – menschliche Mehrwerte ermittelt und im nächsten Schritt adäquate KI-gestützte Workflows konzipiert und in Praxisumgebungen implementiert werden (vgl. Abschnitt \ref{krueger:subsec:implementierung}).\footnote{Angesichts des hohen Entwicklungstempos in der modernen KI-Forschung (vgl. Abschnitt \ref{krueger:subsec:tech_grundlagen}) gilt es hier auch immer, mögliche künftige Potenziale dieser Technologien im Blick zu behalten.} Den Funktionsumfang und das aufgabenspezifische Leistungsniveau von aktuellen LLMs zu bestimmen, ist keine triviale Aufgabe, da die Affordanzen dieser Mehrzweck-KI-Technologien auf den ersten Blick unklar bleiben – d. h., im Gegensatz zu Spezialsystemen wie beispielsweise MÜ-Systemen \glqq{}sagen\grqq{} LLMs ihren Nutzer:innen nicht unmittelbar, was sie mit ihnen tun sollen. Die Bestimmung des aufgabenspezifischen Leistungsniveaus und der menschlichen Eingriffe, die zur erfolgreichen Erledigung der jeweiligen KI-gestützten Aufgaben erforderlich sind, kann aus einer Prozessperspektive unter dem Schlagwort \textit{Expert in the Loop} \citep[vgl.][]{slator_slator_2022} gefasst werden, gemäß dem menschliche Expert:innen durch KI-Technologien nicht vollständig ersetzt werden, sondern weiterhin in KI-gestützte Produktionsprozesse eingebunden bleiben und in diesen Prozessen mindestens eine Supervisionsrolle übernehmen, bei suboptimaler KI-Leistung in die Prozesse eingreifen und die Verantwortung für die Qualität des Endprodukts tragen.\footnote{Aus einer Kognitionsperspektive kann man bei dieser Komplementarität von Mensch und KI von einem \textit{hybriden System}, aus einer Handlungsperspektive von einer \textit{kollaborativen Agency} (vgl. Abschnitt \ref{krueger:subsec:implementierung}) sprechen.} Der Mehrzweck-KI-Charakter und der damit einhergehende breite Funktionsumfang von aktuellen LLMs hat außerdem das Risiko maschineller Zirkularitäten zur Folge, die bei der Ausgestaltung KI-gestützter Produktionsprozesse möglichst vermieden werden sollten. So könnte beispielsweise im Fachübersetzen ein- und dasselbe LLM dazu genutzt werden, einen Ausgangstext mit Blick auf dessen maschinelle Übersetzung zu präeditieren, diesen Text maschinell zu übersetzen, den Zieltext dann einem automatischen Post-Editing zu unterziehen und im Anschluss ggf. noch eine Qualitätsbewertung des Ergebnisses durchzuführen. Im Sinne einer Zirkularitätsvermeidung und damit einhergehenden Risikostreuung sollten diese Arbeitsgänge möglichst jedoch auf unterschiedliche Modelle und/oder menschliche Expert:innen distribuiert werden.

\subsection{Interaktion}

Unter dieser Überschrift werden in dem skizzierten KI-Kompetenzrahmen relevante Aspekte der Mensch-KI-Interaktion modelliert. Hier sind zunächst einmal die verfügbaren Interaktionsmodalitäten relevant. Kurzfristig wird sich diese Interaktion wahrscheinlich noch auf die \glqq{}traditionellen\grqq{} Modalitäten (primär schriftliche, vermehrt aber auch mündliche Interaktion) beschränken. Angesichts der Multimodalität aktueller LLMs sind mittelfristig aber sicherlich weitere Modalitäten wie eine Blick- oder eine Gestensteuerung denkbar (die allerdings mit einer invasiveren Nutzungsdatenerhebung einhergehen). Das KI-spezifische Pre- und Post-Editing nimmt Anleihen beim Pre-/Post-Editing für die maschinelle Übersetzung, allerdings sind diese Arbeitsgänge bei LLMs auch in Zusammenhang mit anderen Texttransformationen möglich. So könnte beispielsweise in der technischen Redaktion die Entwicklerdokumentation zu einem technischen Produkt zunächst präeditiert und dann an ein LLM übergeben werden, das daraus die Entwurfsfassung einer Bedienungsanleitung generiert (die dann wieder einem nachgelagerten menschlichen Post-Editing unterzogen werden könnte). Das adäquate Prompting von LLMs stellt ebenfalls eine wichtige KI-Kompetenz dar, zumal die sprachliche Qualität eines Prompts unmittelbare Auswirkungen auf die Qualität des LLM-Outputs haben kann. Ein solches Prompting kann entweder iterativ-dialogisch erfolgen, d. h., der Output eines LLMs wird ‚im Gespräch‘ mit dem Modell sukzessive verfeinert, oder es wird von vorneherein ein Best-Practice-Prompt für die zu erledigende Aufgabe formuliert\footnote{Eine ausführliche Übersicht zum Best-Practice-Prompting von LLMs für die Aufgabe maschinelle Übersetzung findet sich beispielsweise in \citet[311--317]{kruger_reflections_2023}.}, wobei natürlich auch hier wieder eine anschließende iterativ-dialogische Verfeinerung des LLM-Outputs möglich ist. Auf der Kognitionsebene sind zunächst mögliche Verschiebungen im Bereich der textrezeptiven und textproduktiven Kompetenzen zu berücksichtigen, beispielsweise eine potenziell stärkere Relevanz textrezeptiver Kompetenzen bei der Übernahme der Supervisionsrolle und der Qualitätssicherung oder eine potenzielle Verschiebung textproduktiver Kompetenzen auf das Prompting in LLM-gestützten Produktionsprozessen. In einem hybriden Mensch-KI-System ist zudem ein Bewusstsein für emergente kognitive Effekte positiver oder auch negativer Art erforderlich. Im Idealfall werden in einem solchen hybriden System die Schwächen des Systemelements KI durch die Stärken des Systemelements Mensch ausgeglichen und umgekehrt, wodurch es zu einer Intelligenz-Augmentation\footnote{Gemäß \citet[381]{ng_conceptualizing_2021} handelt es sich bei dem Begriff der \textit{Intelligence Augmentation} um „an alternative conceptualization of artificial intelligence (AI) that focuses on AI’s assistive role, emphasizing the fact that cognitive technology is designed to enhance human intelligence rather than simply replacing it.“} (beispielsweise in Form einer kognitiven Entlastung des Menschen durch die KI oder in Form von kreativen Impulsen durch die KI) kommt. Allerdings können sich die beiden Systemelemente auch in negativer Weise beeinflussen, man könnte hier im Gegensatz zu einer Augmentation von einer \glqq{}Intelligenzhemmung\grqq{} sprechen. Diese kann sich beispielsweise in einer Stagnation der Kompetenzentwicklung (z. B. bei Studierenden) oder einem Kompetenzverlust (bei ausgebildeten Expert:innen) unter dem permanenten Einfluss von LLMs ausdrücken (vgl. die kurze Diskussion zu Deskilling in Abschnitt \ref{krueger:sec:automatisierung}). Ein KI-induziertes Priming, also eine kognitive Vorprägung des menschlichen Systemelements durch den Output einer KI, ist mit Blick auf die MÜ gut belegt \citep[vgl. exemplarisch][55]{schaeffer_language_2016} und wird häufig zu den sprachlichen Phänomenen \textit{Machine Translationese} und \textit{Post-Editese} \citep[vgl. u. a.][]{daems_translation_2017} in Bezug gesetzt. Künftig wird sich eine solche artifiziell ge- oder verformte Sprache sicherlich auch in anderen LLM erzeugten oder LLM-gestützt erzeugten Textarten wiederfinden, man könnte hier allgemein von \textit{LLM-ese} sprechen. Aus einer Handlungsperspektive wird derzeit zudem durch LLMs das Verhältnis von menschlicher und maschineller Agency neu austariert, wobei beispielsweise \citet[80]{van_lier_understanding_2023} dafür plädiert, diese beiden Arten von Wirkpotenzialen in dem Begriff der \glqq{}kollaborativen Agency\grqq{} zusammenfließen zu lassen. Aus dieser Perspektive bilden Mensch und KI im Zusammenspiel einen handelnden Agenten, wobei der Mensch in dieser Konfiguration als autonomer Part die Supervision des nicht-autonomen KI-Parts übernimmt (vgl. ebd.).

\subsection{Implementierung}
\label{krueger:subsec:implementierung}

In dieser Dimension wird die Integration von KI-Technologien in Praxisworkflows in Translation und Fachkommunikation modelliert. Diese Dimension ist stark von dem DataLit\textsuperscript{MT} Framework und dem Professional Machine Translation Literacy Framework (und hier insbesondere von der Dimension \textit{Economic MT literacy}) inspiriert. So nimmt beispielsweise die erste Teildimension \textit{Aufbau einer KI-Kultur} Anleihen bei der Teildimension \textit{Establishing a data culture} des DataLit\textsuperscript{MT} Frameworks. Es geht hierbei um die Bildung eines grundsätzlichen Bewusstseins dafür, dass in einem gegebenen Anwendungskontext bestimmte Aufgaben gestützt durch Daten/KI-Modelle bearbeitet werden können, sowie um die Schaffung entsprechender Rahmenbedingungen (z. B. Entwicklung von Leitlinien/Schulungen zum Einsatz von KI-Modellen in Unternehmenskontexten). Die Auswahl konkreter KI-Anbieter/Modelle sowie die Prozessgestaltung stehen in Wechselwirkung zu den Überlegungen bezüglich des Funktionsumfangs und des aufgabenspezifischen Leistungsniveaus aktueller KI-Technologien sowie der erforderlichen menschlichen Mehrwerte (vgl. Abschnitt \ref{krueger:subsec:domaenenspezifische}). Diese Prozessgestaltung hat nicht nur eine technische, sondern auch eine ergonomische und eine soziotechnische Dimension, die beispielsweise in der Translationswissenschaft mit Blick auf die maschinelle Übersetzung und andere Translationstechnologien bereits umfassend reflektiert wurde \citep[vgl. exemplarisch][]{ehrensberger-dow_socio-technical_2017}. Zur Qualitätskontrolle und -sicherung in KI-gestützten Produktionsprozessen liegen in der Translationswissenschaft ebenfalls umfangreiche Befunde vor, wieder mit primärem Fokus auf der MÜ (vgl. die Teildimensionen \textit{Automatic MT quality evaluation/estimation} und \textit{Manual MT quality evaluation} im Professional MT Literacy Framework). Gleiches gilt für die Aufwandsermittlung/Preisberechnung in KI-gestützten Produktionsprozessen (vgl. die Teildimensionen \textit{Effort estimation/measurement in MTPE} und \textit{Price calculation in MTPE} im selben Framework). Im Kontext der Praxisimplementierung von KI-Technologien sind außerdem entsprechende Risiken zu berücksichtigen, die sich primär in die Felder \textit{Katastrophale Inhaltsfehler}, \textit{Urheberrecht} und \textit{Datensicherheit} unterteilen lassen. Auch hier können wieder entsprechende translationswissenschaftliche Befunde zur maschinellen Übersetzung \citep[vgl. exemplarisch][]{canfora_risks_2020} für eine breitere KI-Risikobetrachtung fruchtbar gemacht werden. Für die rechtskonforme Implementierung von KI-Technologien sind außerdem Kenntnisse maßgeblicher KI-Rechtsrahmen relevant, beispielsweise der jüngst von der Europäischen Union verabschiedeten KI-Verordnung \citep[vgl.][]{eu-parlament_legislative_2024}.

\subsection{Ethische/Gesellschaftliche Aspekte}
\label{krueger:subsec:ethische}

Die letzte Dimension des hier skizzierten Kompetenzrahmens befasst sich mit ethischen/gesellschaftlichen Aspekten und schlägt eine Brücke von domänenspezifischen KI-Kompetenzen (wie diese hier für den Bereich Translation und Fachkommunikation besprochen werden) zu einer breiteren gesamtgesellschaftlichen AI Literacy. Eine KI-induzierte soziale Potenzierung oder Depotenzierung kann beispielsweise anhand des Bourdieu’schen Begriffsinstrumentariums analysiert werden. So gibt es in der Translationswissenschaft Analysen dazu, wie menschliche Übersetzer:innen durch die maschinelle Übersetzung unter Preisdruck gesetzt und gleichzeitig deren Expertenkompetenzen durch diese Technologie delegitimiert werden können, was eine Reduzierung von deren ökonomischen und sozialen Kapital zur Folge haben kann (vgl. exemplarisch \cite{kenny_ethics_2022}). Gesellschaftlich relevant ist ebenfalls die Möglichkeit zur Generierung toxischer Outputs unterschiedlicher Art durch LLMs, wenn beispielsweise das Alignment dieser Modelle durch sog. \textit{Jailbreak Prompting} (vgl. \cite{yong_low-resource_2023}) unterlaufen wird. Dabei handelt es sich um speziell formulierte Prompts, mit denen gezielt die integrierten Sicherheitsmechanismen von LLMs umgangen werden können. Gleiches gilt für das Manipulationspotenzial dieser Technologien, das aus deren Fähigkeit zur täuschend echten Imitation menschlicher Texte und inzwischen auch menschlicher Stimmen und Gesichter erwächst. In Translation und Fachkommunikation wäre eine solche Manipulation beispielsweise im Rahmen der Auftragsakquise/-vergabe oder des allgemeinen Projektmanagements denkbar und könnte durch eine entsprechende Pflicht zur Kennzeichnung KI-generierter Inhalte unterbunden werden (vgl. Abschnitt \ref{krueger:subsec:tech_grundlagen}). Bei dem Aspekt der epistemischen Gewalt und/oder Verzerrung und der Reproduktion von sozialem Bias geht es um das Risiko der Fehldarstellung gesellschaftlicher Realitäten durch KI-Modelle aufgrund von entsprechenden Verzerrungen in deren Trainingsdaten (vgl. exemplarisch \cite{vanmassenhove_gender_2024} zu Gender Bias in maschineller Übersetzung und LLMs). Aus ethischer/gesellschaftlicher Perspektive bedarf es ebenfalls eines Bewusstseins für das materielle und das immaterielle Substrat aktueller KI-Technologien sowie für die mit der Nutzung dieser Technologien verbundenen potenziellen sozialen und ökologischen Folgekosten \citep[vgl. die umfangreiche populärwissenschaftliche Darstellung in][]{crawford_atlas_2021}. Und schließlich ist aus einer ethischen und einer gesellschaftlichen Perspektive auch die Fähigkeit zur Durchführung einer domänenspezifischen oder gesamtgesellschaftlichen Technikfolgenabschätzung im Hinblick auf aktuelle KI-Technologien relevant. Es kann sicherlich mit gewissem Recht behauptet werden, dass die Translationswissenschaft angesichts ihrer inhärenten Interdisziplinarität sowie ihrer umfangreichen Vorerfahrung mit MÜ-induzierten Automatisierungsprozessen hierfür als geeigneter Impulsgeber fungieren könnte.

\section{Fazit und Ausblick}

In diesem Beitrag habe ich die aus leistungsstarken Mehrzweck-KI-Technologien wie multimodalen LLMs erwachsenden neuen Automatisierungspotenziale in Translation und Fachkommunikation diskutiert und aus einer Upskilling-Perspektive heraus eine Reihe von domänenspezifischen KI-Kompetenzen skizziert, die aufseiten von translatorischen/fachkommunikativen \textit{AI-Experts in the Loop} angesichts dieser Automatisierungspotenziale womöglich künftig erforderlich werden. In einem nächsten Schritt sind für die hier vorgeschlagenen Kompetenzen geeignete Kompetenzstufen zu definieren und entsprechende Kompetenzdeskriptoren zu formulieren, wie dies beispielsweise im Rahmen von DataLit\textsuperscript{MT} in Form einer entsprechenden Kompetenzmatrix getan wurde \citep[vgl.][289-290]{kruger_artificial_2023}. Auch sind – ebenfalls analog zu DataLit\textsuperscript{MT} – Überlegungen zur didaktischen Operationalisierung des hier skizzierten Kompetenzrahmens anzustellen, damit Studierende und weitere Akteure aus Translation und Fachkommunikation die vorgeschlagenen (und womöglich noch weitere) Kompetenzen – wahrscheinlich in unterschiedlicher Kombination und auf unterschiedlichen Niveaus – erwerben können. Einen geeigneten Rahmen für eine solche didaktische Operationalisierung könnte beispielsweise das internationale Erasmus+-Konsortium \textit{LT-LiDER: Language and Translation – Literacy in Digital Environments and Resources}\footnote{\url{http://lt-lider.eu/}} unter Leitung der Universitat Autònoma de Barcelona bilden. Ein Ziel dieses Konsortiums ist die Entwicklung digitaler Lehrinhalte zur Vermittlung allgemeiner Digitalkompetenzen und spezifischer KI-Kompetenzen in translatorischen Kontexten. Mit dieser und weiteren Initiativen wird für den Bereich Translation und Fachkommunikation der in Abschnitt \ref{krueger:sec:mtliteracy} geäußerten Annahme Rechnung getragen, dass eine adäquate AI Literacy womöglich zu den wichtigsten Kompetenzbündeln des 21. Jahrhunderts gehören wird. 

\sloppy\printbibliography[heading=subbibliography,notkeyword=this]
\cleardoublepage
\end{document}
