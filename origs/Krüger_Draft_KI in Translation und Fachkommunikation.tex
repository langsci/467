% This file was converted to LaTeX by Writer2LaTeX ver. 1.4
% see http://writer2latex.sourceforge.net for more info
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb,amsfonts,textcomp}
\usepackage{array}
\usepackage{hhline}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, urlcolor=blue}
\usepackage{graphicx}
% footnotes configuration
\makeatletter
\renewcommand\thefootnote{\arabic{footnote}}
\makeatother
% Text styles
\newcommand\textstyleTiteli[1]{#1}
% Headings and outline numbering
\makeatletter
\renewcommand\section{\@startsection{section}{1}{0.25in}{0.1665in}{0.0835in}{\normalfont\normalsize\fontsize{18pt}{21.6pt}\selectfont\rmfamily\bfseries\raggedright}}
\renewcommand\subsection{\@startsection{subsection}{2}{0.25in}{0.222in}{0.0835in}{\normalfont\normalsize\fontsize{16pt}{19.2pt}\selectfont\rmfamily\bfseries\raggedright}}
\renewcommand\@seccntformat[1]{\csname @textstyle#1\endcsname{\csname the#1\endcsname}\csname @distance#1\endcsname}
\setcounter{secnumdepth}{0}
\newcommand\@distancesection{}
\newcommand\@textstylesection[1]{#1}
\newcommand\@distancesubsection{}
\newcommand\@textstylesubsection[1]{#1}
\makeatother
\raggedbottom
% Paragraph styles
\renewcommand\familydefault{\rmdefault}
\newenvironment{stylelsAbstract}{\setlength\leftskip{0.5in}\setlength\rightskip{0.5in}\setlength\parindent{0in}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{12pt}{14.4pt}\selectfont\itshape\writerlistlabel\ignorespaces}{\unskip\vspace{0.111in plus 0.0111in}\par}
\newenvironment{styleStandard}{\setlength\leftskip{0cm}\setlength\rightskip{0cm plus 1fil}\setlength\parindent{0cm}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{12pt}{14.4pt}\selectfont\writerlistlabel\ignorespaces}{\unskip\vspace{0.111in plus 0.0111in}\par}
\newenvironment{stylecaption}{\setlength\leftskip{0cm}\setlength\rightskip{0cm plus 1fil}\setlength\parindent{0cm}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0.0835in plus 0.00835in}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{10pt}{12.0pt}\selectfont\itshape\writerlistlabel\ignorespaces}{\unskip\vspace{0.0835in plus 0.00835in}\par}
% List styles
\newcommand\writerlistleftskip{}
\newcommand\writerlistparindent{}
\newcommand\writerlistlabel{}
\newcommand\writerlistremovelabel{\aftergroup\let\aftergroup\writerlistparindent\aftergroup\relax\aftergroup\let\aftergroup\writerlistlabel\aftergroup\relax}
\title{}
\author{Author}
\date{2024-05-23}
\begin{document}
\title{Künstliche Intelligenz in Translation und Fachkommunikation – \newline
Skizze eines Kompetenzrahmens}
\maketitle

\begin{stylelsAbstract}
In diesem Kapitel wird ein KI-Kompetenzrahmen für Translation und Fachkommunikation skizziert, dessen Notwendigkeit sich aus den jüngsten Entwicklungen im Bereich der sprachbezogenen Künstlichen Intelligenz (KI) – insbesondere im Bereich der Large Language Models (LLMs) – ergibt. Zunächst wird kurz das Verhältnis von neuronaler maschineller Übersetzung (NMÜ) und LLMs diskutiert und im Anschluss das Spektrum translatorischer/fachkommunikativer Arbeitsgänge dargestellt, die insbesondere durch Mehrzweck-KI-Technologien wie LLMs (teil-)automatisiert werden können. Daran an schließt eine Diskussion der angesichts dieser Automatisierung von Translation und Fachkommunikation erforderlichen Digitalkompetenzen, insbesondere in den Bereichen maschinelle Übersetzung, Daten und Künstliche Intelligenz im Allgemeinen. Die entsprechenden Kompetenzbündel MT Literacy, Data Literacy und AI Literacy sowie deren Schnittstellen werden diskutiert und es wird ein daraus abgeleiteter KI-Kompetenzrahmen für Translation und Fachkommunikation skizziert. Im Anschluss werden die einzelnen Dimensionen dieses Kompetenzrahmens im Detail dargestellt und punktuell auf mögliche praktische Anwendungskontexte bezogen.
\end{stylelsAbstract}

\section[Automatisierung und Digitalkompetenzen in Translation und Fachkommunikation]{Automatisierung und Digitalkompetenzen \newline
in Translation und Fachkommunikation}
\begin{styleStandard}
Seitdem die Autoren des in der Translationswissenschaft zu einer gewissen Berühmtheit gelangten ALPAC-Reports (ALPAC 1966) vor fast 60 Jahren dem damaligen Leistungspotenzial der maschinellen Übersetzung (MÜ) ein ungenügendes Zeugnis ausstellten und die Verlagerung künftiger Forschungsbemühungen weg von der \textit{maschinellen} Übersetzung und hin zur \textit{rechnergestützten} Übersetzung empfahlen\footnote{\ „[T]here is no immediate or predictable prospect of useful machine translation. […] Machine-aided translation may be important avenue towards better, quicker, and cheaper translation.” (ALPAC 1966:32).}, ist der Automatisierungsgrad des Übersetzungsprozesses sukzessive erhöht worden (vgl. den historischen Überblick in Chan 2023). Die im ALPAC-Report noch geschmähte MÜ hat spätestens mit dem Siegeszug des Machine-Learning-Paradigmas in der Forschung zur Künstlichen Intelligenz Anfang/Mitte der 2010er Jahre in ihrer Ausprägung als neuronale maschinelle Übersetzung ein beachtliches Leistungsniveau erreicht und kann heute sicherlich mit gutem Recht als translatorische Leittechnologie bezeichnet werden. Ein Meilenstein in der NMÜ- und der breiteren KI-Forschung war die Entwicklung des Transformers (vgl. Vaswani et al. 2017), einer speziellen Ausprägung eines neuronalen Netzes, die besonders gut für die Verarbeitung natürlicher Sprache geeignet ist. Der ursprünglich für die MÜ konzipierte Transformer bildete später auch die Architekturgrundlage für sogenannte Large Language Models (LLMs) wie beispielsweise die GPT-Modelle von OpenAI, die Claude-Modelle von Cohere oder die Gemini-Modelle von Google. LLMs verfügen über die Eigenschaft des „In-Context Learning“ (Brown et al. 2020:3), d. h., sie können durch natürlichsprachliches Prompting mit zahlreichen sprachbezogenen Aufgaben über die maschinelle Übersetzung hinaus betraut werden. Dementsprechend werden diese Modelle – u a. in der aktuellen KI-Gesetzgebung der Europäischen Union – auch als „general-purpose AI technologies“ (Madiega 2023:1), zu Deutsch ‚Mehrzweck-KI-Technologien‘, bezeichnet. Bei aktuellen Modellen wie beispielsweise GPT-4o (vgl. OpenAI 2024) handelt es sich außerdem um \textit{multimodale LLMs} (vgl. Zhang et al. 2024), die neben Schriftsprache auch andere Modalitäten wie Bilder, Videos und Audiosignale verarbeiten können. Diese Funktionsvielfalt multimodaler LLMs hat zur Folge, dass eine große Zahl von Arbeitsgängen nicht nur im Übersetzen, sondern auch im verwandten translatorischen Arbeitsfeld des Dolmetschens und in der dem Übersetzen ebenfalls wesensverwandten technischen Redaktion (im Folgenden: Translation und Fachkommunikation) durch diese Modelle (teil-)automatisiert bzw. unterstützt werden können. Dies ist in Abbildung 1 exemplarisch dargestellt.
\end{styleStandard}

\begin{styleStandard}
  [Warning: Image ignored] % Unhandled or unsupported graphics:
%\includegraphics[width=5.4335in,height=3.2638in,width=\textwidth]{KrgerDraftKIinTranslationundFachkommunikation-img001.jpg}
 
\end{styleStandard}

\begin{stylecaption}
Abbildung 1: Spektrum der durch LLMs potenziell (teil-)automatisierbaren Arbeitsgänge in Translation und Fachkommunikation (CC BY-SA 4.0)
\end{stylecaption}

\begin{styleStandard}
In der Übersetzung können LLMs beispielsweise über die ‚klassische‘ maschinelle Übersetzung hinaus mit Aufgaben im Bereich der Qualitätsbewertung, der Qualitätsoptimierung (Pre-/Post-Editing, maschinelles Lektorat), der Informationsrecherche/Terminologiearbeit oder womöglich auch im Bereich des Projektmanagements betraut werden. LLMs, die zur Verarbeitung mündlicher Sprache in der Lage sind, können außerdem potenziell zum maschinellen Dolmetschen eingesetzt werden, und die Fähigkeit generativer Sprachmodelle zur autonomen Textproduktion oder auch zur einsprachigen Texttransformation (z. B. Entwicklerdokumentation → Bedienungsanleitung) könnte in der technischen Redaktion genutzt werden.\footnote{\ Auch im Dolmetschen und der technischen Redaktion ist selbstverständlich eine LLM-Unterstützung in den Bereichen Informationsrecherche/Terminologiearbeit, Qualitätsbewertung und (womöglich eher in der technischen Redaktion als im Dolmetschen) Qualitätsoptimierung möglich.} Da moderne LLMs nicht nur natürliche Sprachen sondern i~d.~R. auch Formalsprachen (z. B. Programmiersprachen wie Python, Auszeichnungssprachen wie XML oder Textmuster wie reguläre Ausdrücke) beherrschen, können sie auch in diesem Bereich eine Unterstützung bieten, wenn beispielsweise im Übersetzen oder der technischen Redaktion reguläre Ausdrücke zur Identifizierung und ggf. Manipulation bestimmter Zeichenketten (E-Mail-Adressen, Telefonnummern, Maßeinheiten usw.) geschrieben werden müssen. 
\end{styleStandard}

\begin{styleStandard}
Eine solche (Teil-)Automatisierung translatorischer/fachkommunikativer Arbeitsgänge kann aus einer Kompetenzperspektive unterschiedlich bewertet werden. So nimmt Sandrini (2022:51) in seinem \textit{Translatoren-Obsoleszenz-Zyklus} Teilaufgaben des Übersetzungsprozesses in den Blick, die bei einer Erhöhung des Automatisierungsgrades von einem Computer übernommen werden können. Aufseiten menschlicher Übersetzer:innen werden diese Aufgaben damit obsolet, was womöglich entsprechende Kompetenzverluste mit sich bringt (so entfällt z. B. durch den Einsatz von Terminologiedatenbanken die Notwendigkeit der Memorisierung von Fachtermini und durch den Einsatz von MÜ-Systemen die Notwendigkeit der Anfertigung einer Rohübersetzung, vgl. ebd.). In einem ähnlichen Zusammenhang sprechen Schatzky/Schwartz (2015:9) von einem möglichen „Deskilling“, das mit einem übermäßigen Technologieeinsatz verbunden sein kann. Olohan (2017:278) weist dagegen – wieder mit Blick auf das Übersetzen – darauf hin, dass mit einer Erhöhung des translatorischen Automatisierungsgrades auch ein „upskilling of translators“ einhergehen kann. Denn schließlich resultiert ein höherer Automatisierungsgrad häufig in einer höheren Komplexität der jeweiligen (teil-)automatisierten Prozesse, woraus wiederum neue prozessanalytische, prozessorganisatorische und technologische Kompetenzanforderungen erwachsen (vgl. hierzu auch Krüger 2018). Dieser Gedanken eines technologieinduzierten Upskillings soll in diesem Beitrag aufgegriffen und mit Blick auf die zuvor besprochenen LLMs weiter ausgearbeitet werden. Es könnte in diesem Zusammenhang argumentiert werden, dass diese Mehrzweck-KI-Technologien nur dann in adäquater Weise in Praxisworkflows integriert und ihr Potenzial zur (Teil-)Automatisierung translatorischer/fachkommunikativer Arbeitsgänge nur dann voll ausgeschöpft werden können, wenn die Nutzer:innen dieser Modelle über entsprechende Kompetenzen entlang mehrerer Dimensionen verfügen, wie dies in dem in Abschnitt 3 skizzierten Kompetenzrahmen abgebildet werden soll. Empirisch gestützt wird diese Annahme beispielsweise durch eine gemeinsame Umfrage von Slator und der Association of Language Companies aus dem Jahr 2023, bei der 34~\% der befragten Sprachdienstleister KI und Big Data als die wichtigsten Kompetenzfelder der kommenden Jahre nannten (vgl. Edwards 2023a).
\end{styleStandard}

\section[2. MT Literacy, Data Literacy und AI Literacy und ihre Schnittstellen]{2. MT Literacy, Data Literacy und AI Literacy \newline
und ihre Schnittstellen}
\begin{styleStandard}
Aus dem Blickwinkel \textit{Upskilling als Reaktion auf Automatisierung} sind in der Translationswissenschaft in den letzten Jahren insbesondere drei Bündel von Digitalkompetenzen diskutiert worden, die mit Blick auf das Erkenntnisinteresse des aktuellen Beitrags von besonderer Relevanz sind. Diese drei Kompetenzbündel und ihre Schnittstellen sind in Abbildung 2 dargestellt.
\end{styleStandard}

\begin{styleStandard}
  [Warning: Image ignored] % Unhandled or unsupported graphics:
%\includegraphics[width=5.1917in,height=1.7453in,width=\textwidth]{KrgerDraftKIinTranslationundFachkommunikation-img002.jpg}
 
\end{styleStandard}

\begin{stylecaption}
Abbildung 2: MT Literacy, Data Literacy und AI Literacy sowie deren Schnittstellen (CC BY-SA 4.0)
\end{stylecaption}

\begin{styleStandard}
In Zusammenhang mit der zunehmenden Relevanz der maschinellen Übersetzung sowohl in der Sprachindustrie als auch in der breiteren Gesellschaft haben Bowker/Ciro (2019) den Begriff der \textit{Machine Translation Literacy} geprägt, der von O’Brien/Ehrensberger-Dow (2020:146) definiert wird als „knowing how MT works, how it can be useful in a particular context, and what the implications are of using MT for specific communicative needs“. Mit Blick auf das professionelle Fachübersetzen habe ich darauf aufbauend den Begriff der \textit{Professional MT Literacy} vorgeschlagen. Dieser beschreibt “the full range of MT-related competences professional translators (and other language professionals) may require in order to participate successfully in the various phases of the MT-assisted professional translation process” (Krüger 2022:249). Der zweite im aktuellen Zusammenhang relevante Begriff ist der der \textit{Data Literacy}, definiert als „the ability to collect, manage, evaluate, and apply data, in a critical manner“ (Ridsdale et al. 2015:11). Die Schnittstelle zwischen MT und Data Literacy bildet die korpusbasierte maschinelle Übersetzung, insbesondere in ihrer Ausprägung als NMÜ, die nicht, wie frühe regelbasierte MÜ-Systeme, mit explizitem linguistischen Wissen operiert, sondern mit umfangreichen Übersetzungskorpora trainiert wird und aus ihren Trainingsdaten eigene Repräsentationen und Übersetzungsmuster erlernt (Representation Learning im Rahmen des Machine-Learning-Paradigmas). Die Schnittstelle zwischen MT Literacy und Data Literacy wurde ausführlich in dem Projekt \textit{DataLit}\textit{\textsuperscript{MT}} bearbeitet, in dessen Rahmen Lerninhalte zur Vermittlung von Datenkompetenzen im Kontext der NMÜ entwickelt wurden (vgl. Hackenbuchner/Krüger 2023).\footnote{\ Projektergebnisse von DataLit\textsuperscript{MT}: \url{https://itmk.github.io/The-DataLitMT-Project/} (24.04.2024)} Das dritte im aktuellen Kontext relevante Kompetenzbündel firmiert unter dem Namen \textit{Artificial Intelligence Literacy }und wird von Long/Magerko (2020:1) definiert als „a set of competencies that enables individuals to critically evaluate AI technologies; communicate and collaborate effectively with AI; and use AI as a tool online, at home, and in the workplace.“ Angesichts der Ubiquität leistungsstarker KI-Technologien in modernen Gesellschaften (KI als „Everyware“ im Sinne von Greenfield 2006) sind zunehmend Stimmen zu vernehmen, laut denen AI Literacy neben traditionellen Lese-, Schreib- und Rechenkompetenzen sowie allgemeinen Digitalkompetenzen zu den wichtigsten Kompetenzbündeln des 21. Jahrhunderts gehört (vgl. Ng et al., 2021:9). Die Schnittstelle zwischen AI Literacy und Data Literacy bildet das bereits angesprochene Machine-Learning-Paradigma innerhalb der übergeordneten KI-Forschung, in dessen Rahmen neuronale Netze mit umfangreichen Trainingsdatenbeständen trainiert werden und aus diesen Trainingsdaten Repräsentationen und Muster erlernen (vgl. die Erläuterungen zur korpusbasierten MÜ als spezifischer Ausprägung eines Machine-Learning-Systems). Diese untrennbare Verflechtung von Algorithmen und Daten in modernen KI-Technologien hat damit auch eine entsprechende Verflechtung von Data Literacy und AI Literacy zur Folge. Die Schnittstelle zwischen AI Literacy und MT Literacy bilden die bereits besprochenen LLMs, die aus der NMÜ-Forschung hervorgegangen sind und auf einem ähnlichen Funktionsprinzip wie die NMÜ beruhen (mit dem Transformer als gemeinsamer Architekturgrundlage). Angesichts dieser Genealogie kann bei der theoretischen Ausarbeitung und didaktischen Operationalisierung einer translatorischen/fachkommunikativen AI Literacy auf Vorarbeiten zu einer Professional MT Literacy und einer MÜ-spezifischen Data Literacy zurückgegriffen werden (vgl. die Diskussion im nachstehenden Abschnitt).
\end{styleStandard}

\section[Skizze eines KI{}-Kompetenzrahmens für Translation und Fachkommunikation]{Skizze eines KI-Kompetenzrahmens \newline
für Translation und Fachkommunikation}
\begin{styleStandard}
Der nachstehend skizzierte KI-Kompetenzrahmen für Translation und Fachkommunikation basiert in Teilen auf drei bestehenden Kompetenzrahmen: \textit{1)} dem im Kontext von DataLit\textsuperscript{MT} entwickelten \textit{Professional MT Literacy Framework} (vgl. Krüger 2022:250), \textit{2)} dem \textit{DataLit}\textit{\textsuperscript{MT}}\textit{ Framework} (einem in demselben Projekt entwickelten MÜ-spezifischen Data Literacy Framework, vgl. ebd.:260) und \textit{3)} dem \textit{AI Literacy Framework} von Long/Magerko (2020). Im Professional MT Literacy Framework werden die im professionellen Fachübersetzen erforderlichen MÜ-Kompetenzen auf fünf Dimensionen verteilt (\textit{technical MT literacy}, \textit{linguistic MT literacy}, \textit{economic MT literacy}, \textit{societal MT literacy} und \textit{cognitive MT literacy}), die jeweils in weitere Teildimensionen aufgefächert sind. Das DataLit\textsuperscript{MT} Framework modelliert den Datenlebenszyklus innerhalb eines MÜ-Projektes und ist in die fünf Dimensionen \textit{Data context}, \textit{Data planning}, \textit{Data collection/production}, \textit{Data evaluation} und \textit{Data use} unterteilt (jeweils wieder in weitere Teildimensionen aufgefächert). Bei dem AI Literacy Framework von Long/Magerko (2020) handelt es sich um einen generischen, sprich nicht domänenspezifischen, Kompetenzrahmen, der entlang der fünf Fragen \textit{What is AI?}, \textit{What can AI do?}, \textit{How does AI work?}, \textit{How should AI be used?} und \textit{How do people perceive AI? }strukturiert ist.\footnote{\ Das Professional MT Literacy Framework und das DataLit\textsuperscript{MT} Framework sowie die Schnittstelle zwischen diesen beiden Kompetenzrahmen werden in Krüger (2022) im Detail beschrieben. Das AI Literacy Framework von Long \& Magerko sowie die Schnittstelle zwischen diesem und den beiden vorgenannten Kompetenzrahmen werden in Krüger (2023) eingehend besprochen.}\textit{ }Der auf Grundlage dieser konzeptuellen Vorläufer entwickelte KI-Kompetenzrahmen für Translation und Fachkommunikation in seiner Entwurfsfassung ist in Abbildung 3 dargestellt.
\end{styleStandard}

\begin{styleStandard}
  [Warning: Image ignored] % Unhandled or unsupported graphics:
%\includegraphics[width=6.7752in,height=8.0835in,width=\textwidth]{KrgerDraftKIinTranslationundFachkommunikation-img003.png}
 
\end{styleStandard}

\begin{stylecaption}
Abbildung 3: Skizze eines KI-Kompetenzrahmens für Translation und Fachkommunikation (CC BY-SA 4.0)
\end{stylecaption}

\begin{styleStandard}
Im Folgenden werden die fünf Dimensionen des Kompetenzrahmens genauer besprochen und dabei einzelne Teilkompetenzen exemplarisch fokussiert.
\end{styleStandard}

\subsection[Technische Grundlagen]{Technische Grundlagen}
\begin{styleStandard}
Die erste Dimension des skizzierten Kompetenzrahmens befasst sich mit den technischen Grundlagen moderner KI-Verfahren. Hierunter fallen grundlegende Kenntnisse der Funktionsweise aktueller KI-Technologien sowie des Trainings dieser Technologien, ein Bewusstsein für die Verflechtung von KI-Modellen und deren Trainingsdaten (wodurch gleichzeitig die Anschlussfähigkeit des Kompetenzrahmens an einschlägige Datenkompetenzrahmen hergestellt wird) sowie Kenntnisse der Funktionsweise und der Notwendigkeit der Kennzeichnung KI-generierter Inhalte\footnote{\ Eine solche Kennzeichnung ist insbesondere im Kontext des modernen KI-Technologien innewohnenden Manipulationspotenzials zu sehen, das in dem skizzierten Kompetenzrahmen unter \textit{Ethische/gesellschaftliche Aspekte} (vgl. Abschnitt 3.5) aufgeführt ist.}, wie dies jüngst beispielsweise in einer Executive Order der US-Regierung vorgeschrieben wurde (vgl. Edwards 2023b). In der Translationswissenschaft werden Forderungen nach technischen Grundkenntnissen im Bereich moderner Translationstechnologien (speziell der NMÜ) häufig mit dem Empowerment von Übersetzer:innen begründet, das mitunter eingeschränkt ist, wenn diese Übersetzer:innen die Funktionsweise solcher Technologien aufgrund von deren ‚Blackbox‘-Charakter nicht nachvollziehen können.\footnote{\ Vgl. hierzu Kenny (2019:438): „Increased opacity […] is a particular cause for concern for humans required to work with contemporary MT systems because it can limit their ability to intervene in translation workflows, thus undermining agendas of translator empowerment […].“} Dieser Befund gilt sicherlich auch für Mehrzweck-KI-Technologien wie LLMs sowie für die verwandten Berufsbilder des Dolmetschens und der technischen Redaktion. An dieser Stelle wird allerdings auch direkt ersichtlich, dass der hier skizzierte Kompetenzrahmen in seiner aktuellen Form lediglich eine Momentaufnahme der sehr dynamischen KI-Landschaft darstellt und möglicherweise schon bald an neue Entwicklungen in diesem Bereich angepasst werden muss. So wird hier beispielsweise der Transformer als aktuelle State-of-the-Art-Architektur im KI-Bereich aufgeführt. Allerdings werden derzeit auch alternative Modellarchitekturen (z. B. sog. ‚State Space Models‘ wie \textit{Mamba}, vgl. Gu \& Dao 2023) erforscht, die dem Transformer in Zukunft Konkurrenz machen oder diesen womöglich auch als Leitarchitektur ersetzen könnten.
\end{styleStandard}

\subsection[Domänenspezifische Performanz]{Domänenspezifische Performanz}
\begin{styleStandard}
Im Kontext der domänenspezifischen Performanz geht es zunächst einmal um ein Bewusstsein für den Funktionsumfang von modernen KI-Technologien (vgl. die Diskussion in Abschnitt 1), was auch ein Verständnis der verfügbaren Ein- und Ausgabemodalitäten dieser Technologien umfasst. Aufbauend darauf können dann das aufgabenspezifische Leistungsniveau dieser Technologien und – damit zusammenhängend – menschliche Mehrwerte ermittelt und im nächsten Schritt adäquate KI-gestützte Workflows konzipiert und in Praxisumgebungen implementiert werden (vgl. Abschnitt 3.4).\footnote{\ Angesichts des hohen Entwicklungstempos in der modernen KI-Forschung (vgl. Abschnitt 3.1) gilt es hier auch immer, mögliche künftige Potenziale dieser Technologien im Blick zu behalten.} Den Funktionsumfang und das aufgabenspezifische Leistungsniveau von aktuellen LLMs zu bestimmen, ist keine triviale Aufgabe, da die Affordanzen dieser Mehrzweck-KI-Technologien auf den ersten Blick unklar bleiben – d. h., im Gegensatz zu Spezialsystemen wie beispielsweise MÜ-Systemen ‚sagen‘ LLMs ihren Nutzer:innen nicht unmittelbar, was sie mit ihnen tun sollen. Die Bestimmung des aufgabenspezifischen Leistungsniveaus und der menschlichen Eingriffe, die zur erfolgreichen Erledigung der jeweiligen KI-gestützten Aufgaben erforderlich sind, kann aus einer Prozessperspektive unter dem Schlagwort \textit{Expert in the Loop} (vgl. Slator 2022) gefasst werden, gemäß dem menschliche Expert:innen durch KI-Technologien nicht vollständig ersetzt werden, sondern weiterhin in KI-gestützte Produktionsprozesse eingebunden bleiben und in diesen Prozessen mindestens eine Supervisionsrolle übernehmen, bei suboptimaler KI-Leistung in die Prozesse eingreifen und die Verantwortung für die Qualität des Endprodukts tragen.\footnote{\ Aus einer Kognitionsperspektive kann man bei dieser Komplementarität von Mensch und KI von einem \textit{hybriden System}, aus einer Handlungsperspektive von einer \textit{kollaborativen Agency} (vgl. Abschnitt 3.3) sprechen.} Der Mehrzweck-KI-Charakter und der damit einhergehende breite Funktionsumfang von aktuellen LLMs hat außerdem das Risiko maschineller Zirkularitäten zur Folge, die bei der Ausgestaltung KI-gestützter Produktionsprozesse möglichst vermieden werden sollten. So könnte beispielsweise im Fachübersetzen ein- und dasselbe LLM dazu genutzt werden, einen Ausgangstext mit Blick auf dessen maschinelle Übersetzung zu präeditieren, diesen Text maschinell zu übersetzen, den Zieltext dann einem automatischen Post-Editing zu unterziehen und im Anschluss ggf. noch eine Qualitätsbewertung des Ergebnisses durchzuführen. Im Sinne einer Zirkularitätsvermeidung und damit einhergehenden Risikostreuung sollten diese Arbeitsgänge möglichst jedoch auf unterschiedliche Modelle und/oder menschliche Expert:innen distribuiert werden.
\end{styleStandard}

\subsection[Interaktion]{Interaktion}
\begin{styleStandard}
Unter dieser Überschrift werden in dem skizzierten KI-Kompetenzrahmen relevante Aspekte der Mensch-KI-Interaktion modelliert. Hier sind zunächst einmal die verfügbaren Interaktionsmodalitäten relevant. Kurzfristig wird sich diese Interaktion wahrscheinlich noch auf die ‚traditionellen‘ Modalitäten (primär schriftliche, vermehrt aber auch mündliche Interaktion) beschränken. Angesichts der Multimodalität aktueller LLMs sind mittelfristig aber sicherlich weitere Modalitäten wie eine Blick- oder eine Gestensteuerung denkbar (die allerdings mit einer invasiveren Nutzungsdatenerhebung einhergehen). Das KI-spezifische Pre- und Post-Editing nimmt Anleihen beim Pre-/Post-Editing für die maschinelle Übersetzung, allerdings sind diese Arbeitsgänge bei LLMs auch in Zusammenhang mit anderen Texttransformationen möglich. So könnte beispielsweise in der technischen Redaktion die Entwicklerdokumentation zu einem technischen Produkt zunächst präeditiert und dann an ein LLM übergeben werden, das daraus die Entwurfsfassung einer Bedienungsanleitung generiert (die dann wieder einem nachgelagerten menschlichen Post-Editing unterzogen werden könnte). Das adäquate Prompting von LLMs stellt ebenfalls eine wichtige KI-Kompetenz dar, zumal die sprachliche Qualität eines Prompts unmittelbare Auswirkungen auf die Qualität des LLM-Outputs haben kann. Ein solches Prompting kann entweder iterativ-dialogisch erfolgen, d. h., der Output eines LLMs wird ‚im Gespräch‘ mit dem Modell sukzessive verfeinert, oder es wird von vorneherein ein Best-Practice-Prompt für die zu erledigende Aufgabe formuliert\footnote{\ Eine ausführliche Übersicht zum Best-Practice-Prompting von LLMs für die Aufgabe maschinelle Übersetzung findet sich beispielsweise in Krüger (2023:311–317).}, wobei natürlich auch hier wieder eine anschließende iterativ-dialogische Verfeinerung des LLM-Outputs möglich ist. Auf der Kognitionsebene sind zunächst mögliche Verschiebungen im Bereich der textrezeptiven und textproduktiven Kompetenzen zu berücksichtigen, beispielsweise eine potenziell stärkere Relevanz textrezeptiver Kompetenzen bei der Übernahme der Supervisionsrolle und der Qualitätssicherung oder eine potenzielle Verschiebung textproduktiver Kompetenzen auf das Prompting in LLM-gestützten Produktionsprozessen. In einem hybriden Mensch-KI-System ist zudem ein Bewusstsein für emergente kognitive Effekte positiver oder auch negativer Art erforderlich. Im Idealfall werden in einem solchen hybriden System die Schwächen des Systemelements KI durch die Stärken des Systemelements Mensch ausgeglichen und umgekehrt, wodurch es zu einer Intelligenz-Augmentation\footnote{\ Gemäß Szczerbicki/Nguyen (2021:381) handelt es sich bei dem Begriff der \textit{Intelligence Augmentation} um „an alternative conceptualization of artificial intelligence (AI) that focuses on AI’s assistive role, emphasizing the fact that cognitive technology is designed to enhance human intelligence rather than simply replacing it.“} (beispielsweise in Form einer kognitiven Entlastung des Menschen durch die KI oder in Form von kreativen Impulsen durch die KI) kommt. Allerdings können sich die beiden Systemelemente auch in negativer Weise beeinflussen, man könnte hier im Gegensatz zu einer Augmentation von einer ‚Intelligenzhemmung‘ sprechen. Diese kann sich beispielsweise in einer Stagnation der Kompetenzentwicklung (z. B. bei Studierenden) oder einem Kompetenzverlust (bei ausgebildeten Expert:innen) unter dem permanenten Einfluss von LLMs ausdrücken (vgl. die kurze Diskussion zu Deskilling in Abschnitt 1). Ein KI-induziertes Priming, also eine kognitive Vorprägung des menschlichen Systemelements durch den Output einer KI, ist mit Blick auf die MÜ gut belegt (vgl. exemplarisch Carl/Schaeffer 2019:55) und wird häufig zu den sprachlichen Phänomenen \textit{Machine Translationese} und \textit{Post-Editese} (vgl. u. a. Daems et al. 2017) in Bezug gesetzt. Künftig wird sich eine solche artifiziell ge- oder verformte Sprache sicherlich auch in anderen LLM erzeugten oder LLM-gestützt erzeugten Textarten wiederfinden, man könnte hier allgemein von \textit{LLM-ese} sprechen. Aus einer Handlungsperspektive wird derzeit zudem durch LLMs das Verhältnis von menschlicher und maschineller Agency neu austariert, wobei beispielsweise van Lier (2023:80) dafür plädiert, diese beiden Arten von Wirkpotenzialen in dem Begriff der ‚kollaborativen Agency‘ zusammenfließen zu lassen. Aus dieser Perspektive bilden Mensch und KI im Zusammenspiel einen handelnden Agenten, wobei der Mensch in dieser Konfiguration als autonomer Part die Supervision des nicht-autonomen KI-Parts übernimmt (vgl. ebd.).
\end{styleStandard}

\subsection[Implementierung]{Implementierung}
\begin{styleStandard}
In dieser Dimension wird die Integration von KI-Technologien in Praxisworkflows in Translation und Fachkommunikation modelliert. Diese Dimension ist stark von dem DataLit\textsuperscript{MT} Framework und dem Professional Machine Translation Literacy Framework (und hier insbesondere von der Dimension \textit{Economic MT literacy}) inspiriert. So nimmt beispielsweise die erste Teildimension \textit{Aufbau einer KI-Kultur} Anleihen bei der Teildimension \textit{Establishing a data culture} des DataLit\textsuperscript{MT} Frameworks. Es geht hierbei um die Bildung eines grundsätzlichen Bewusstseins dafür, dass in einem gegebenen Anwendungskontext bestimmte Aufgaben gestützt durch Daten/KI-Modelle bearbeitet werden können, sowie um die Schaffung entsprechender Rahmenbedingungen (z. B. Entwicklung von Leitlinien/Schulungen zum Einsatz von KI-Modellen in Unternehmenskontexten). Die Auswahl konkreter KI-Anbieter/Modelle sowie die Prozessgestaltung stehen in Wechselwirkung zu den Überlegungen bezüglich des Funktionsumfangs und des aufgabenspezifischen Leistungsniveaus aktueller KI-Technologien sowie der erforderlichen menschlichen Mehrwerte (vgl. Abschnitt 3.2). Diese Prozessgestaltung hat nicht nur eine technische, sondern auch eine ergonomische und eine soziotechnische Dimension, die beispielsweise in der Translationswissenschaft mit Blick auf die maschinelle Übersetzung und andere Translationstechnologien bereits umfassend reflektiert wurde (vgl. exemplarisch Ehrensberger-Dow/Massey 2017). Zur Qualitätskontrolle und -sicherung in KI-gestützten Produktionsprozessen liegen in der Translationswissenschaft ebenfalls umfangreiche Befunde vor, wieder mit primärem Fokus auf der MÜ (vgl. die Teildimensionen \textit{Automatic MT quality evaluation/estimation} und \textit{Manual MT quality evaluation} im Professional MT Literacy Framework). Gleiches gilt für die Aufwandsermittlung/Preisberechnung in KI-gestützten Produktionsprozessen (vgl. die Teildimensionen \textit{Effort estimation/measurement in MTPE} und \textit{Price calculation in MTPE} im selben Framework). Im Kontext der Praxisimplementierung von KI-Technologien sind außerdem entsprechende Risiken zu berücksichtigen, die sich primär in die Felder Katastrophale Inhaltsfehler, Urheberrecht und Datensicherheit unterteilen lassen. Auch hier können wieder entsprechende translationswissenschaftliche Befunde zur maschinellen Übersetzung (vgl. exemplarisch Canfora/Ottmann 2020) für eine breitere KI-Risikobetrachtung fruchtbar gemacht werden. Für die rechtskonforme Implementierung von KI-Technologien sind außerdem Kenntnisse maßgeblicher KI-Rechtsrahmen relevant, beispielsweise des jüngst von der Europäischen Union verabschiedeten KI-Gesetzes (vgl. Europäisches Parlament 2023).
\end{styleStandard}

\subsection[Ethische/Gesellschaftliche Aspekte]{Ethische/Gesellschaftliche Aspekte}
\begin{styleStandard}
Die letzte Dimension des hier skizzierten Kompetenzrahmens befasst sich mit ethischen/gesellschaftlichen Aspekten und schlägt eine Brücke von domänenspezifischen KI-Kompetenzen (wie diese hier für den Bereich Translation/Fachkommunikation besprochen werden) zu einer breiteren gesamtgesellschaftlichen AI Literacy. Eine KI-induzierte soziale Potenzierung oder Depotenzierung kann beispielsweise anhand des Bourdieu’schen Begriffsinstrumentariums analysiert werden. So gibt es in der Translationswissenschaft Analysen dazu, wie menschliche Übersetzer:innen durch die maschinelle Übersetzung unter Preisdruck gesetzt und gleichzeitig deren Expertenkompetenzen durch diese Technologie delegitimiert werden können, was eine Reduzierung von deren ökonomischem und sozialem Kapital zur Folge haben kann (vgl. exemplarisch Moorkens 2022). Gesellschaftlich relevant ist ebenfalls die Möglichkeit zur Generierung toxischer Outputs unterschiedlicher Art durch LLMs, wenn beispielsweise das Alignment dieser Modelle durch sog. \textit{Jailbreak Prompting} (vgl. Yong et al. 2024) unterlaufen wird. Gleiches gilt für das Manipulationspotenzial dieser Technologien, das aus deren Fähigkeit zur täuschend echten Imitation menschlicher Texte und inzwischen auch menschlicher Stimmen und Gesichter erwächst. In Translation und Fachkommunikation wäre eine solche Manipulation beispielsweise im Rahmen der Auftragsakquise/-vergabe oder des allgemeinen Projektmanagements denkbar und könnte durch eine entsprechende Pflicht zur Kennzeichnung KI-generierter Inhalte unterbunden werden (vgl. Abschnitt 3.1). Bei dem Aspekt der epistemischen Gewalt/Verzerrung und der Reproduktion von sozialem Bias geht es um das Risiko der Fehldarstellung gesellschaftlicher Realitäten durch KI-Modelle aufgrund von entsprechenden Verzerrungen in deren Trainingsdaten (vgl. exemplarisch Vanmassenhove 2024 zu Gender Bias in maschineller Übersetzung und LLMs). Aus ethischer/gesellschaftlicher Perspektive bedarf es ebenfalls eines Bewusstseins für das materielle und das immaterielle Substrat aktueller KI-Technologien sowie für die mit der Nutzung dieser Technologien verbundenen potenziellen sozialen und ökologischen Folgekosten (vgl. die umfangreiche populärwissenschaftliche Darstellung in Crawford 2021). Und schließlich ist aus einer ethischen/gesellschaftlichen Perspektive auch die Fähigkeit zur Durchführung einer domänenspezifischen oder gesamtgesellschaftlichen Technikfolgenabschätzung im Hinblick auf aktuelle KI-Technologien relevant. An anderer Stelle (Krüger zur Veröffentlichung eingereicht) habe ich argumentiert, dass beispielsweise die Translationswissenschaft angesichts ihrer inhärenten Interdisziplinarität sowie ihrer umfangreichen Vorerfahrung mit MÜ-induzierten Automatisierungsprozessen hierfür ein geeigneter Impulsgeber sein könnte.
\end{styleStandard}

\section[Fazit und Ausblick]{Fazit und Ausblick}
\begin{styleStandard}
In diesem Beitrag habe ich die aus leistungsstarken Mehrzweck-KI-Technologien wie multimodalen LLLMs erwachsenden neuen Automatisierungspotenziale in Translation und Fachkommunikation diskutiert und aus einer Upskilling-Perspektive heraus eine Reihe von domänenspezifischen KI-Kompetenzen skizziert, die aufseiten von translatorischen/fachkommunikativen \textit{AI-Experts in the Loop} angesichts dieser Automatisierungspotenziale womöglich künftig erforderlich werden. In einem nächsten Schritt sind für die hier vorgeschlagenen Kompetenzen geeignete Kompetenzstufen zu definieren und entsprechende Kompetenzdeskriptoren zu formulieren, wie dies beispielsweise im Rahmen von DataLit\textsuperscript{MT} in Form einer entsprechenden Kompetenzmatrix getan wurde (vgl. Hackenbuchner/Krüger 2023:289–290). Auch sind – ebenfalls analog zu DataLit\textsuperscript{MT} – Überlegungen zur didaktischen Operationalisierung des hier skizzierten Kompetenzrahmens anzustellen, damit Studierende und weitere Akteure aus Translation und Fachkommunikation die vorgeschlagenen (und womöglich noch weitere) Kompetenzen – wahrscheinlich in unterschiedlicher Kombination und auf unterschiedlichen Niveaus – erwerben können. Einen geeigneten Rahmen für eine solche didaktische Operationalisierung könnte beispielsweise das internationale Erasmus+-Konsortium \textit{LT-LiDER: Language and Translation – Literacy in Digital Environments and Resources}\footnote{\ \url{http://lt-lider.eu/}} unter Leitung der Universitat Autònoma de Barcelona (vgl. Sanchéz-Gijón et al. im Erscheinen) bilden. Ein Ziel dieses Konsortiums ist die Entwicklung digitaler Lehrinhalte zur Vermittlung allgemeiner Digitalkompetenzen und spezifischer KI-Kompetenzen in translatorischen Kontexten (vgl. ebd.). Mit dieser und weiteren Initiativen wird für den Bereich Translation und Fachkommunikation der in Abschnitt 2 geäußerten Annahme Rechnung getragen, dass eine adäquate AI Literacy womöglich zu den wichtigsten Kompetenzbündeln des 21. Jahrhunderts gehören wird. 
\end{styleStandard}

\section[Literatur]{Literatur}
\begin{styleStandard}
ALPAC (1966): \textit{Languages and machines: Computers in translation and linguistics. A report by the Automatic Language Processing Advisory Committee, Division of Behavioural Sciences, National Academy of Sciences, National Research Council}. Washington, DC: National Academy of Sciences, National Research Council. \url{https://doi.org/10.17226/9547}.
\end{styleStandard}

\begin{styleStandard}
Benaich, Nathan/Hogarth, Ian (2022): \textit{State of AI report 2022}. \url{https://www.stateof.ai/} (24.04. 2024).
\end{styleStandard}

\begin{styleStandard}
Bowker, Lynne/Ciro, Jairo Buitrago (2019): \textit{Machine translation and global research: Towards improved machine translation literacy in the scholarly community}. Bingley: Emerald Publishing.
\end{styleStandard}

\begin{styleStandard}
Brown, Tom/Mann, Benjamin/Ryder, Nick/Subbiah, Melanie/Kaplan, Jared D./Dhariwal, Prafulla/Neelakantan, Arvind/Shyam, Pranav/Sastry, Girish/Askell, Amanda/Agarwal, Sandhini/Herbert-Voss, Ariel/Krueger, Gretchen/Henighan, Tom/Child, Rewon/Ramesh, Aditya/Ziegler, Daniel/Wu, Jeffrey/Winter, Clemens/Hesse, Chris/Chen, Mark/Sigler, Eric/Litwin, Mateusz/Gray, Scott/Chess, Benjamin/Clark, Jack/Berner, Christopher/McCandlish, Sam/Radford, Alec/Sutskever, Ilya/Amodei, Dario (2020): Language models are few-shot learners. In: Larochelle, Hugo/Ranzato, Marc’Aurelio/Hadsell, Raja/Balcan, Maria-Florina/Lin, Hsuan-Tien (Hg.): \textit{Advances in neural information processing systems 33 (NeurIPS 2020)}, 1–25. \url{https://papers.nips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html} (29.04.2024).
\end{styleStandard}

\begin{styleStandard}
Canfora, Carmen/Ottmann, Angelika (2020): Risks in neural machine translation. \textit{Translation Spaces} 9(1), 58–77. \url{https://doi.org/10.1075/ts.00021.can}.
\end{styleStandard}

\begin{styleStandard}
Carl, Michael/Schaeffer, Moritz (2019): Outline of a relevance theoretical model of machine translation post-editing. In: Li, Defeng/Lei, Victoria/Lai, Cheng/He, Yuanjian (Hg.): \textit{Researching cognitive processes of translation}. Singapur: Springer, 49–67. \url{https://doi.org/10.1007/978-981-13-1984-6_3}.
\end{styleStandard}

\begin{styleStandard}
Chan, Sin-wai (2023): The development of translation technology 1967–2023. In: Chan, Sin-wai (Hg.): \textit{The Routledge encyclopedia of translation technology}. London u.~a.: Routledge, 3–41.
\end{styleStandard}

\begin{styleStandard}
Crawford, Kate (2021): \textit{Atlas of AI. Power, politics, and the planetary costs of artificial intelligence}. Yale University Press.
\end{styleStandard}

\begin{styleStandard}
Daems, Joke/De Clercq, Orphée/Macken, Lieve (2017): Translationese and post-editese: How comparable is comparable quality? \textit{Linguistica Antverpiensia, New Series – Themes in Translation Studies}, \textit{16}, 89–103. \url{https://doi.org/10.52034/lanstts.v16i0.434}.
\end{styleStandard}

\begin{styleStandard}
Edwards, Alex (2023a): Customer service and AI-expertise top list of key employee skills, ALC survey finds. \textit{Slator}. \url{https://slator.com/customer-service-ai-expertise-top-list-of-key-employee-skills-alc-survey-finds/} (30.04.2024).
\end{styleStandard}

\begin{styleStandard}
Edwards, Alex (2023b): US to require watermarking of ‘synthetic content’ created for government. \textit{Slator}. \url{https://slator.com/us-require-watermarking-synthetic-content-created-for-government/} (29.04.2024).
\end{styleStandard}

\begin{styleStandard}
Ehrensberger-Dow, Maureen/Massey, Gary (2017): Socio-technical issues in professional translation practice. \textit{Translation Spaces} 6(1), 104–121. \url{https://doi.org/10.1075/ts.6.1.06ehr}.
\end{styleStandard}

\begin{styleStandard}
Europäisches Parlament (2023): KI-Gesetz: erste Regulierung der künstlichen Intelligenz. \url{https://www.europarl.europa.eu/topics/de/article/20230601STO93804/ki-gesetz-erste-regulierung-der-kunstlichen-intelligenz} (21.05.2024).
\end{styleStandard}

\begin{styleStandard}
Greenfield, Adam (2006): \textit{Everyware: The dawning age of ubiquitous computing}. Berkeley: New Riders.
\end{styleStandard}

\begin{styleStandard}
Gu, Albert/Dao, Tri (2023): Mamba: Linear-time sequence modelling with selective state spaces. \textit{arXiv}. \url{https://doi.org/10.48550/arXiv.2312.00752}.
\end{styleStandard}

\begin{styleStandard}
Hackenbuchner, Janiça/Krüger, Ralph (2023): DataLit\textsuperscript{MT} – Teaching data literacy in the context of machine translation literacy. In: Nurminen, Mary/Brenner, Judith/Koponen, Maarit/Latomaa, Sirkku/Mikhailov, Mikhail/Schierl, Frederike/Ranasinghe, Tharindu/Vanmassenhove, Eva/Alvarez Vidal, Sergi/Aranberri, Nora/Nunziatini, Mara/Parra Escartìn, Carla/Forcada, Mikel/Popovic, Maja/Scarton, Carolina/Moniz, Helena (Hg.): \textit{Proceedings of the 24}\textit{\textsuperscript{th}}\textit{ annual conference of the European Association for Machine Translation (EAMT 2023)}. European Association for Machine Translation, 285–293. \url{https://aclanthology.org/2023.eamt-1.28/} (24.04.2024).
\end{styleStandard}

\begin{styleStandard}
Kenny, Dorothy (2019): Machine translation. In: Rawling, Piers/Wilson, Philip (Hg.): \textit{The Routledge handbook of translation and philosophy}. London u.~a.: Routledge, 428–445.
\end{styleStandard}

\begin{styleStandard}
Krüger, Ralph (2018): Technologieinduzierte Verschiebungen in der Tektonik der Translationskompetenz. \textit{trans-kom} 11(1), 104–137. \url{http://www.trans-kom.eu/bd11nr01/trans-kom_11_01_06_Krueger_Tektonik.20180712.pdf} (30.04.2024).
\end{styleStandard}

\begin{styleStandard}
Krüger, Ralph (2022): Integrating professional machine translation literacy and data literacy. \textit{Lebende Sprachen} 67(2), 247–282. \url{https://doi.org/10.1515/les-2022-1022}.
\end{styleStandard}

\begin{styleStandard}
Krüger, Ralph (2023): AI literacy for the language industry – with particular emphasis on recent large language models such as GPT-4. \textit{Lebende Sprachen} 68(2), 283–330. \url{https://doi.org/10.1515/les-2023-0024}.
\end{styleStandard}

\begin{styleStandard}
Krüger, Ralph (zur Veröffentlichung eingereicht): Übersetzen und Dolmetschen in einer KI-saturierten Welt. Oder: Zu welchem Ende studiert man heute Translationswissenschaft? \textit{Lebende Sprachen}.
\end{styleStandard}

\begin{styleStandard}
Long, Duri/Magerko, Brian (2020): What is AI literacy? Competencies and design considerations. In: Bernhaupt, Regina/Mueller, Florian/Verweij, David/Andres, Josh (Hg.): \textit{CHI '20: Proceedings of the 2020 CHI conference on human factors in computing systems}. Association for Computing Machinery, 1–16. \url{https://doi.org/10.1145/3313831.3376727}.
\end{styleStandard}

\begin{styleStandard}
Madiega, Tambiama (2023): General-purpose artificial intelligence. \textit{Wissenschaftlicher Dienst des Europäischen Parlaments}. \url{https://www.europarl.europa.eu/RegData/etudes/ATAG/2023/745708/EPRS_ATA(2023)745708_EN.pdf} (24.04.2024).
\end{styleStandard}

\begin{styleStandard}
Moorkens, Joss (2022): Ethics and machine translation. In: Kenny, Dorothy (Hg.): \textit{Machine translation for everyone. Empowering users in the age of artificial intelligence}. Berlin: Language Science Press, 121–140. \url{https://doi.org/10.5281/zenodo.6653406}.
\end{styleStandard}

\begin{styleStandard}
Ng, Davy Tsz Kit/Leung, Jac Ka Lok/Chu, Samuel Kai Wah/Qiao, Maggie Shen (2021): Conceptualizing AI literacy: An exploratory review. \textit{Computers and Education: Artificial Intelligence} 2, 1–11. \url{https://doi.org/10.1016/j.caeai.2021.100041}.
\end{styleStandard}

\begin{styleStandard}
O’Brien, Sharon/Ehrensberger-Dow, Maureen (2020): MT literacy—a cognitive view. \textit{Translation, Cognition \& Behaviour }3(2), 145–164. \url{https://doi.org/10.1075/tcb.00038.obr}.
\end{styleStandard}

\begin{styleStandard}
Olohan, Maeve (2017): Technology, translation and society. \textit{Target} 29(2), 264–283. \url{https://doi.org/10.1075/target.29.2.04olo}.
\end{styleStandard}

\begin{styleStandard}
OpenAI (2024): Hello GPT-4o. \url{https://openai.com/index/hello-gpt-4o/} (21.05.2024).
\end{styleStandard}

\begin{styleStandard}
Ridsdale, Chantel/Rothwell, James/Smit, Mike/Ali-Hassan, Hossam/Bliemel, Michael/Irvine, Dean/Kelley, Daniel/Matwin, Stan/Wuetherick, Brad (2015): \textit{Strategies and best practices for data literacy education. Knowledge synthesis report}. Dalhousie University. \url{http://hdl.handle.net/10222/64578} (24.04.2024).
\end{styleStandard}

\begin{styleStandard}
Sánchez-Gijón, Pilar/Torres Simon, Esther/Vargas Urpí, Mireia/Aranberri, Nora/Ciobanu, Dragos/Guerberof-Arenas, Ana/Hackenbuchner, Janiça/Kenny, Dorothy/Krüger, Ralph/Moorkens, Joss/Rios, Miguel/Rivas Ginel, Isabel/Rossi, Caroline/Secara, Alina/Toral, Antonio (im Erscheinen): Literacy in digital environments and resources (LT-LiDER). In: \textit{Proceedings of the 24}\textit{\textsuperscript{th}}\textit{ annual conference of the European Association for Machine Translation (EAMT 2024)}. European Association for Machine Translation.
\end{styleStandard}

\begin{styleStandard}
Sandrini, Peter (2022): „It‘s the economy, stupid.“ Discussing the translator‘s business against the background of a changing techno-economic landscape. \textit{Translation Matters} 4(2), 49–62. \url{http://dx.doi.org/10.21747/21844585/tm4_2a4}.
\end{styleStandard}

\begin{styleStandard}
Schatsky, David/Schwartz, Jeff (2015): Redesigning work in an era of cognitive technologies. \textit{Deloitte Review }17. \url{https://www2.deloitte.com/content/dam/Deloitte/tr/Docu-ments/technology-media-telecommunications/redesigningworkcognitivetechnologies.pdf} (24.04.2024).
\end{styleStandard}

\begin{styleStandard}
Slator (2022a): Slator machine translation expert-in-the-loop report. \textit{Slator}. \url{https://slator.com/machine-translation-expert-in-the-loop-report/} (30.04.2024).
\end{styleStandard}

\begin{styleStandard}
Szczerbicki, Edward/Nguyen, Ngoc T. (2021): Intelligence augmentation and amplification: Approaches, tools, and case studies. \textit{Cybernetics and Systems} 53(5), 381–383. \url{https://doi.org/10.1080/01969722.2021.2018551}.
\end{styleStandard}

\begin{styleStandard}
van Lier, Maud (2023): Understanding large language models through the lens of artificial agency. In: Grahn, Håkan, Borg, Anton and Martin Boldt /Hg.): \textit{35}\textit{\textsuperscript{th}}\textit{ annual workshop of the Swedish Artificial Intelligence Society (SAIS 2023)}, 79–84. \url{https://doi.org/10.3384/ecp199008}.
\end{styleStandard}

\begin{styleStandard}
Vanmassenhove, Eva (2024): Gender bias in machine translation and the era of large language models. \textit{arXiv}. \url{https://doi.org/10.48550/arXiv.2401.10016}.
\end{styleStandard}

\begin{styleStandard}
Vaswani, Ashish/Shazeer, Noam/Parmar, Niki/Uszkoreit, Jakob/Jones, Llion/Gomez, Aidan N./Kaiser, Łukasz/Polosukhin, Łukasz (2017): Attention is all you need. In: Guyon, Isabelle/von Luxburg, Ulrike/Bengio, Samy/Wallach, Hanna M./Fergus, Rob/Vishwanathan, S.~V.~N./Garnett, Roman (Hg.): \textstyleTiteli{\textit{Advances in neural information processing systems 30 (NIPS 2017)}, 1}–\textstyleTiteli{11}.\textstyleTiteli{\textit{ }}\url{https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html} (24.04.2024).
\end{styleStandard}

\begin{styleStandard}
Yong, Z.-X., Menghini, C., \& Bach, S. H. (2024). Low-resource languages jailbreak GPT-4. \textit{arXiv}. \url{https://doi.org/10.48550/arXiv.2310.02446}.
\end{styleStandard}

\begin{styleStandard}
Zhang, Duzhen/Yu, Yahan/Li, Chenxing/Dong, Jiahua/Su, Dan/Chu, Chenhui/Yu, Dong (2024): MM-LLMs: Recent advances in multimodal large language models. \textit{arXiv}. \url{https://doi.org/10.48550/arXiv.2401.13601}.
\end{styleStandard}
\end{document}
