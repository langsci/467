% This file was converted to LaTeX by Writer2LaTeX ver. 1.4
% see http://writer2latex.sourceforge.net for more info
\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{amsmath}
\usepackage{amssymb,amsfonts,textcomp}
\usepackage{array}
\usepackage{hhline}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, urlcolor=blue}
% footnotes configuration
\makeatletter
\renewcommand\thefootnote{\arabic{footnote}}
\makeatother
% Text styles
\newcommand\textstyleHeadingiiChar[1]{{\fontsize{16pt}{19.2pt}\selectfont \textrm{#1}}}
% Headings and outline numbering
\makeatletter
\renewcommand\section{\@startsection{section}{1}{0.0cm}{0.25in}{0.0555in}{\normalfont\normalsize\fontsize{20pt}{24.0pt}\selectfont\rmfamily\raggedright}}
\renewcommand\@seccntformat[1]{\csname @textstyle#1\endcsname{\csname the#1\endcsname}\csname @distance#1\endcsname}
\setcounter{secnumdepth}{0}
\newcommand\@distancesection{}
\newcommand\@textstylesection[1]{#1}
\makeatother
\raggedbottom
% Paragraph styles
\renewcommand\familydefault{\rmdefault}
\newenvironment{styleSubtitle}{\setlength\leftskip{0cm}\setlength\rightskip{0cm plus 1fil}\setlength\parindent{0cm}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{14pt}{16.8pt}\selectfont\writerlistlabel\ignorespaces}{\unskip\vspace{0in plus 1pt}\par}
\newenvironment{styleTextkrperMaster}{\renewcommand\baselinestretch{1.0}\setlength\leftskip{0in}\setlength\rightskip{0in}\setlength\parindent{0.3937in}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0.0783in plus 0.00783in}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\writerlistlabel\ignorespaces}{\unskip\vspace{0.0783in plus 0.00783in}\par}
\newenvironment{styleZitatMaster}{\setlength\leftskip{0.5118in}\setlength\rightskip{0.5118in}\setlength\parindent{0in}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0.0783in plus 0.00783in}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{10pt}{12.0pt}\selectfont\upshape\writerlistlabel\ignorespaces}{\unskip\vspace{0.0783in plus 0.00783in}\par}
\newenvironment{styleStandard}{\setlength\leftskip{0cm}\setlength\rightskip{0cm plus 1fil}\setlength\parindent{0cm}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\writerlistlabel\ignorespaces}{\unskip\vspace{0in plus 1pt}\par}
\newenvironment{styleBibliography}{\setlength\leftskip{0.5in}\setlength\rightskip{0in plus 1fil}\setlength\parindent{-0.5in}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\writerlistlabel\ignorespaces}{\unskip\vspace{0in plus 1pt}\par}
% List styles
\newcommand\writerlistleftskip{}
\newcommand\writerlistparindent{}
\newcommand\writerlistlabel{}
\newcommand\writerlistremovelabel{\aftergroup\let\aftergroup\writerlistparindent\aftergroup\relax\aftergroup\let\aftergroup\writerlistlabel\aftergroup\relax}
\title{}
\author{Oliver Czulo}
\date{2024-11-18}
\begin{document}
\title{Algorithmische Übersetzung: Die Ideengeschichte vor der Entwicklung der Maschinellen Übersetzung}
\maketitle

\begin{styleSubtitle}
Maria Wolf und Oliver Czulo
\end{styleSubtitle}

\begin{styleSubtitle}
Universität Leipzig
\end{styleSubtitle}

\section{1. Einleitung}
\begin{styleTextkrperMaster}
Der folgende Beitrag skizziert die Ideengeschichte dessen, was wir als \textit{Algorithmische Übersetzung} verstehen, also einer Gruppe von Verfahren mit einer festgelegten Abfolge von vordefinierten Arbeitsschritten, die dem Ziel dienen, eine Übersetzung eines natürlichsprachlichen Ausgangstexts zu erstellen. Die \textit{Maschinelle Übersetzung} sehen wir als Umsetzung algorithmischer Verfahren mittels elektronischer Rechenwerke. Algorithmische Übersetzungsverfahren fassen wir in diesem Beitrag insofern eng, als dass sie Aspekte der Berechenbarkeit und Determiniertheit mindestens in Ansätzen in sich tragen. Wir grenzen sie somit von Modellen für Humanübersetzungsverfahren ab, wiewohl diese Grenzen selbstverständlich fließend sein können.
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Die hier vorgestellten Ansätze datieren vor dem 20. Jahrhundert. Anhand der vorgestellten Ideen wird deutlich, was die Gelehrten antrieb und in welchem historischen Zusammenhang sie agierten: al\nobreakdash-Kind\=\i übersetzte in Bagdad griechische Schriften ins Arabische, Ramon Llull missionierte im Mittelmeerraum, Gottfried Wilhelm Leibniz suchte nach einer Universalsprache, um die Begriffswelt der Menschen zu erschließen, und Johann Joachim Becher wollte den Handel mit fremden Ländern fördern. Die Autoren sind Vordenker des technologischen Fortschritts, den wir in den vergangenen Jahrzehnten erlebt haben. Allerdings ist die Ideengeschichte der Algorithmischen Übersetzung brüchig: Nicht immer beziehen sich die Autoren auf ihre zeitlichen Vorgänger, und auch heute wird in der Literatur zur Maschinellen Übersetzung erfahrungsgemäß eher selten Bezug auf historische Überlegungen genommen.
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Einige der Verfahren sind eng verbunden mit der Kryptologie, wobei kryptographische Verfahren Sprache verschlüsseln und damit auf eine bestimmte Art und Weise kodieren, während kryptoanalytische Verfahren eine solche Kodierung zu entschlüsseln versuchen. Die von DuPont (2019) skizzierte Archäologie der maschinellen Übersetzung umfasst solche Verfahren, die Übersetzung als Dekodierung und Rekodierung verstehen. Die Idee einer Interlingua sucht nach einem Universalcode, der zwischen allen Sprachen vermitteln kann und nicht von den Idiosynkrasien natürlicher Sprachen geplagt ist, während Ansätze zu Plansprachen die Universalisierung einer künstlich geschaffenen Sprache erreichen wollen. Den Wunsch, die Informationen eines Ausgangstextes vollständig aus ihm zu lösen und in der Zielsprache zu generieren, kennzeichnet Stein (2009) als fortwährende Utopie, welche die Geschichte der Maschinellen Übersetzung seit dem 13. Jahrhundert prägt.
\end{styleTextkrperMaster}

\section[2. Entschlüsselungsverfahren nach al{}-Kind\=\i]{2. Entschlüsselungsverfahren nach al-Kind\=\i}
\begin{styleTextkrperMaster}
Die ersten Zeugnisse der Beschreibung von Rechenverfahren zur Übersetzung eines Textes liegen heute in der \textit{Sulaymannja Library} in Istanbul und sind kryptoanalytischer Natur (DuPont 2018; Strick 2009). Im neunten Jahrhundert nach Christus wirkte Ab\=u~Ya[2BF?]q\=ub ibn Ish\=aq al-Kind\=\i (ca.~800-873~n.~C.) in Bagdad und entschlüsselte „schleierhafte“\footnote{Die arabische Schule habe Wörter als Schleier beschrieben, die die Verbindungen zwischen Gedanken und Verstehen verdeckten. Demnach sei Kommunikation der Vermittlungsprozess, um diese Schleier aufzudecken (u. a. DuPont 2018).} Schriftstücke. Seine \textit{Abhandlung über die Entzifferung von verschlüsselten Botschaften} wurde im Jahr 1987 wiederentdeckt. Über al-Kind\=\i (auch Al Kindus) ist bekannt, dass er im Haus der Weisheit\footnote{Von der arabischen Schule ist bekannt, dass sie sich mit Kryptologie beschäftigte und bereits eine feste Terminologie nutzte zur Unterscheidung von zwischen Verschlüsselung und Entschlüsselung, zur Bezeichnung von Ausgangstexten, verschlüsselten Texte und Übersetzungen sowie zur Beschreibung von Methoden und Prozessen. Wieber (1977) gibt einen Einblick in die algorithmischen Verfahren der damaligen Kryptographie.} „mit der Übersetzung wissenschaftlicher Schriften aus verschiedenen Kulturkreisen ins Arabische“ (Strick 2009) beauftragt wurde. Er habe sich dabei vor allem mit den philosophischen Schriften der Griechen beschäftigt, verstand aber selbst kein Griechisch, sondern überarbeitete und kommentierte Übersetzungen seiner Dragomane\footnote{Das arabische Wort tar[1E7?]um\=an habe nicht nur Übersetzende und Dolmetschende bezeichnet, sondern auch „Dechiffreure“ und „Codebrecher“ (Wieber 1977, 257).}, die für die Entschlüsselung der fremden Texte zuständig waren (ebd.). Aufgrund seiner Beiträge zur Geometrie, Arithmetik und Logik und seiner Abhandlung \textit{Über den Intellekt} wird er heute als „erster Philosoph der arabischen Welt“ (ebd.) bezeichnet. Er verfasste auch medizinische Schriften und lehrte seine Schüler Rechenverfahren. Einige Schriften seien später ins Lateinische übersetzt worden, aber viele seiner Werke verloren gegangen (ebd.).
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Al-Kind\=\i war Experte für kryptologische Methoden und linguistische Kenntnisse, die seinerzeit in der arabischen Schule gelehrt und angewandt wurden. Seine o.~g. kryptoanalytische Abhandlung untersucht die arabische Sprache anhand phonetischer und syntaktischer Merkmale sowie anhand der Häufigkeitsverteilung der Buchstaben. Schmeh (2006, 16) beschreibt al-Kind\=\is Methoden als „Ersetzungsverfahren“ und „Umordnungsverfahren“, mit welchen Buchstabenhäufigkeiten analysiert, häufige Wörter erraten und Buchstabenpaare ausgezählt wurden.
\end{styleTextkrperMaster}

\begin{styleZitatMaster}
„Eine Möglichkeit, eine verschlüsselte Botschaft zu entziffern, vorausgesetzt, wir kennen ihre Sprache, besteht darin, einen anderen Klartext in derselben Sprache zu finden, der lang genug ist, um ein oder zwei Blätter zu füllen, und dann zu zählen, wie oft jeder Buchstabe vorkommt. Wir nennen den häufigsten Buchstaben den »ersten«, den zweithäufigsten den »zweiten«, den folgenden den »dritten« und so weiter, bis wir alle Buchstaben in der Klartextprobe durchgezählt haben.
\end{styleZitatMaster}

\begin{styleZitatMaster}
Dann betrachten wir den Geheimtext, den wir entschlüsseln wollen, und ordnen auch seine Symbole. Wir finden das häufigste Symbol und geben ihm die Gestalt des »ersten« Buchstabens der Klartextprobe, das zweithäufigste Symbol wird zum »zweiten« Buchstaben, das dritthäufigste Symbol zum »dritten« und so weiter, bis wir alle Symbole des Kryptogramms, das wir entschlüsseln wollen, auf diese Weise zugeordnet haben.“ (al-Kind\=\i nach Singh 2001, 35).
\end{styleZitatMaster}

\begin{styleTextkrperMaster}
Aus der Perspektive der Gelehrten damals dürfte oft nicht klar gewesen sein, ob das vorliegende Schriftstück in fremder Sprache, in verschlüsselter Sprache oder in beidem vorlag. Dazu kommt, dass es damals noch keine Einheitssprachen, sondern eine unvorstellbare Sprachvarietät gab. Verständlich also, dass al-Kind\=\i nach definierten Rechenschritten suchte – nach einem Algorithmus, der ihm die Arbeit erleichtern würde. Seine statistischen Methoden, z.~B. die Auszählung des Vokal-Konsonanten-Verhältnisses, wurden noch Jahrhunderte später zur Feststellung der Ausgangssprache genutzt\footnote{\ Ein Beispiel hierfür sind die kryptologischen Werke von Leon Battista Alberti. Ein weiteres Beispiel ist der vom Kryptologe William Friedmann Anfang der 1920er Jahre entwickelte Koinzidenzenindex (vgl. DuPont 2018).}.
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Kryptoanalytische Verfahren und Übersetzung sind aufgrund der Natur ihrer Ausgangstexte nicht zu verwechseln. Die (metaphorische) Verbindung der beiden Disziplinen, die jeweils einen eigenen Gegenstand haben und demnach einen anderen Zweck verfolgen, besteht jedoch in der Anwendung von Verfahren, mit denen zunächst der „Code“ des Ausgangstextes bestimmt wird, um somit den Ausgangstext zu „entschlüsseln“ und den Zieltext zu erhalten.\footnote{\ Dafür argumentiert auch DuPont (2018): Er findet den Ursprung maschineller Übersetzung in kryptoanalytischen Verfahren und verbindet die Ideengeschichte von Entschlüsselung und Übersetzung: Beides „crackt“ einen unbekannten Text. DuPont veranschaulicht anhand kryptoanalytischer Verfahren, wie sehr die (gemeinsame) Geschichte durch die Spannung zwischen Rationalismus und Empirismus geprägt ist.} Die Ideengeschichte beider Disziplinen überlappt sich aufgrund gemeinsamer Methoden und der Entwicklung ihrer Automatisierung, die in Programmiersprachen zur Ansteuerung von Maschinen kulminiert.
\end{styleTextkrperMaster}

\section[3. Die ars combinatoria von Ramon Llull]{3. Die \textit{ars combinatoria} von Ramon Llull}
\begin{styleTextkrperMaster}
Der Universalgelehrte Ramon Llull (1232–1316, auch Raimundus Lullus) widmete sich der Christianisierung des Mittelmeerraums, warb für die Lehre der hebräischen und arabischen Sprache an westeuropäischen Universitäten und gilt heute als der Begründer der westeuropäischen Orientalistik. Er entwarf eine Argumentationsmaschine, mit der er weltanschauliche Begriffe vom Lateinischen ins Arabische übertrug. Mit dieser mechanischen Übertragungshilfe habe Llull die Missionierung erleichtern wollen (u. a. Martiny 2018; Zotter 2004, 31).\footnote{\ Zotter (2004) vermutet, dass Llull eine mechanische Unterstützung für christliche Missionare im Sinn hatte, weil Juden und Araber ihm argumentativ überlegen erschienen. Die Macht der Argumentation habe er jedoch unterschätzt, denn er sei auf einer seiner Missionsreisen gesteinigt worden (Zotter 2004).} Sie funktionierte durch übereinanderliegende Drehscheiben\footnote{\ Auch die Kryptologie kennt mechanische Konstruktionen aus verschiedenen Scheiben, so funktionieren z.~B. die Alberti-Chiffren auf diese Weise (DuPont 2018; Schmeh 2006, 19f).}, deren Inhalt miteinander kombiniert werden konnte. Der Auszug aus Llulls Werk (Abbildung 1) zeigt Skizzen dieser Scheiben, auf denen Zeichen, Buchstaben und Begriffe abgebildet sind.
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
[\textbf{Abbildung 1}: Abbildung1\_Llull\_ars\_brevis.jpg, heruntergeladen von \url{https://dhmuseum.uni-trier.de/node/354} (Duda 2016). Dort trägt sie die Bildunterschrift: „Die vier Figuren der ›Ars brevis‹ des Raimundus Lullus (\href{http://dfg-viewer.de/show/?tx_dlf%5Bid%5D=http%3A%2F%2Fzimks68.uni-trier.de%2Fstmatthias%2FT1895%2FT1895-digitalisat.xml&tx_dlf%5Bpage%5D=8&tx_dlf%5Bdouble%5D=0&cHash=f4e40988d0b7f70c9ccb59fa9a0e6493}{Stadtbibliothek und Stadtarchiv Trier, Trier Hs. 1895/1428}, \href{https://creativecommons.org/licenses/by-sa/4.0/deed.de}{CC BY-SA 4.0})“]
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Die Idee der \textit{ars combinatoria} wird heute als herausragend angesehen, da sie Begriffen Zeichen zuweist und über eine Zeichenfolge bestimmte Argumente festhält. Der Inhalt der zu kombinierenden Begriffe in Llulls Kombinatorik beruhe auf grundlegenden Prinzipien, die den drei großen monotheistischen Religionen gemein sind, womit die „konfliktträchtige Tradition der Textinterpretation der jeweiligen heiligen Schriften (Bibel, Talmud, Koran)“ durchbrochen worden sei (Duda 2016). Pring-Mill (2001) beschreibt den „Mikrokosmos“ von Ramon Llull und liefert eine ausführliche Darstellung des Inhalts der Scheiben und der Funktionsweise ihrer Kombinationen. Die Sekundärliteratur ist sich darüber einig, dass Llulls Argumentationsmaschine mehr als ein Übersetzungswerkzeug war und damit die Wahrheit der Menschen erklärbar werden sollte (vgl. u. a. Duda 2016; Martiny 2018). Llull gilt als Vordenker der Informatik, da er versucht, die Gedankenwelt der Menschen in Grundbegriffe zu zerlegen und sie über einen Code miteinander zu kombinieren. Die Idee, Begriffe durch Buchstaben zu ersetzen, also sprachliche Inhalte durch Zeichenfolgen, ihre Kombination durch eine Kodierung festzuhalten und dann auch wieder zu entschlüsseln, gilt heute als der erste Versuch, Sprache mittels einer Maschine zu verarbeiten, denn dieses algorithmische Verfahren ist das Grundprinzip von Programmier- und Maschinensprachen.
\end{styleTextkrperMaster}

\section{4. Leibniz und seine Universalsprache}
\begin{styleTextkrperMaster}
Wie sehr die algorithmischen Verfahren zur Übersetzung durch ihren historischen Kontext und damit auch durch bestimmte weltanschauliche und wissenschaftliche Desiderate geprägt sind, zeigt die Weiterentwicklung von Llulls\textit{ ars combinatoria} durch Gottfried Wilhelm Leibniz (1646-1716).
\end{styleTextkrperMaster}

\begin{styleZitatMaster}
„Wenn man Charaktere oder Zeichen finden könnte, die alle unsere Gedanken genauso rein und klar ausdrücken könnten, wie die Arithmetik Zahlen oder die Analytische Geometrie Linien ausdrückt, dann könnte man in allen Angelegenheiten, soweit sie dem rationalen Denken zugänglich sind, das tun, was man in der Arithmetik und Geometrie tut.“ (Leibniz 1960, 90)
\end{styleZitatMaster}

\begin{styleTextkrperMaster}
Leibniz war überzeugt davon, dass nicht nur Sprachen, sondern letztendlich alles, was wir wahrnehmen, aus einzelnen Einheiten besteht (Monadentheorie\footnote{\ Leibniz‘ Monadologie von 1714 beruht auf der Theorie, dass die Welt aus \textit{Monaden} (griech. \textit{monas} = Einzelteil, Einzelnes, Substanz) zusammengesetzt ist, und erklärt seine Methode, Gegenstände, die er verstehen will, in ihre Einzelteile zu zerlegen und deren Zusammenhang zu erforschen. Die Vorstellung, dass die wahrgenommene Welt aus zusammenhängenden Einheiten bestehe, führte ihn zur Überlegung, dass also die wahrgenommene und gedachte Welt in Einzelteile zerlegbar und ihr Zusammenhang kodifizierbar sei.}) und sich deshalb durch eine Kodierung beschreiben lässt. Er erstellte ein duales Zahlensystem, weshalb ihm die Entwicklung der binären Kodierung zugeschrieben wird und er heute als Vordenker der Informatik gilt (u. a. Breger 2009). Als letzter Universalgelehrter\footnote{\ Leibniz lebte in einer Zeit des wissenschaftlichen Umbruchs: In den Geistes- und Naturwissenschaften kristallisierten sich einzelne Disziplinen heraus und es setzte sich die Auffassung durch, dass Zusammenhänge nicht getrennt von ihren Gegenständen vorliegen und durch eine allgemeine Formel erklärbar seien. } verknüpfte er mathematische und logische Erkenntnisse mit religiösen Konzepten, wobei Wissenschaft für ihn eine Art Universalkenntnis war. So habe Leibniz das binäre Zahlensystem, bei dem alle Zahlen durch Eins und Null kodiert sind, als „Sinnbild der göttlichen Schöpfung“ (Breger 2009, 387) beschrieben: Wenn die Eins „die Einheit oder das Eine“ und die Null „das Nichts oder den Mangel an Existenz“ darstelle, werde ersichtlich, dass „Gott oder die absolute Einheit […] alles aus dem Nichts“ erzeuge (ebd.).
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Leibniz zählt zu den Vertretern der wissenschaftlichen Überzeugung, dass alle Sprachen auf einem gemeinsamen Code beruhen. So verfasste Athanasius~Kircher (1602-1680) auf der Suche nach einer Interlingua als sprachuniversalem Code die \textit{Polygraphia nova et universalis – }eine Plansprache, die den schriftlichen Austausch unter den Völkern ermöglichen sollte und durch die Geheimsprache von Johannes Trithemius (1462\nobreakdash-1516, P\textit{olygraphiæ libri sex}) inspiriert gewesen sei (Strasser 1988). Leibniz‘ c\textit{haracteristica universalis }verfolge die Idee eines „Alphabets des menschlichen Denkens“, welches durch Grundbegriffe alle menschlichen Begriffe umfasse, womit „alle wahren Sätze“ mechanisch gebildet werden könnten (Bedürftig und Murawski 2015, 56). Die erdachte Universalsprache sollte „alle Begriffe der Wissenschaften ausdrücken“ und der „Verständigung der Menschen aller Nationen“ dienen (ebd.).
\end{styleTextkrperMaster}

\begin{styleZitatMaster}
„Und wenn dies geschieht [...], werden zwei Philosophen, die in einen Streit geraten, nicht anders argumentieren als zwei Rechenmeister. Es genügt, dass sie eine Feder in die Hand nehmen, sich vor ein Täfelchen setzen und zueinander sagen: ‚Calculemus!‘ (Rechnen wir!)“ (Leibniz 1890, 7:198f).
\end{styleZitatMaster}

\begin{styleTextkrperMaster}
Hier wird deutlich, dass die Universalsprache nicht ausschließlich als Übersetzungswerkzeug konzipiert wurde, sondern dass durch sie algorithmische Verfahren möglich werden sollten, mit denen die Arbeit der Wissenschaft erleichtert und die Wahrheit zugänglicher würde. Leibniz war überzeugt, dass es „unwürdig“ sei, die Zeit der Gelehrten mit einfachen Rechenaufgaben zu verschwenden und dass mit Maschinen solche Aufgaben schneller und fehlerfrei gelöst werden könnten. So entwarf er unter anderem seine \textit{machina deciphratoria} zur Verschlüsselung und Entschlüsselung von Botschaften.
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Seine Entwürfe für Rechenmaschinen waren für die Entwicklung der Mechanik zur Lösung von mathematischen Problemen ein gewaltiger Fortschritt. Er erfand das Prinzip der Staffelwalze, welches als handschriftliche Skizze in Abbildung 2 zu sehen ist. Die Rechenmaschine auf Abbildung 3 ist ein Originalentwurf von 1690. Seinerzeit fehlte es noch an geeigneten Baumaterialien als technische Voraussetzung für solche feinmechanischen Apparaturen und die Umsetzung seiner Entwürfe bedurfte der Entwicklung und Forschung im Bereich der Feinmechanik.
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
[\textbf{Abbildung 2}: Abbildung2\_Sprossenrad\_leibniz.png. Heruntergeladen von \url{https://commons.wikimedia.org/wiki/File:Sprossenrad_leibniz.png}, dort auch Infos zur Weiterverwendung, keine bessere Auflösung vorhanden.]
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
[\textbf{Abbildung 3: }Abbildung 3\_Leibniz\_Rechenmaschine\_(1960).jpg. Heruntergeladen von \url{https://de.wikipedia.org/wiki/Rechenmaschine#/media/Datei:Leibniz_Rechenmaschine_(1690).jpg}, dort Infos zur Weiterverwendung, 8,4 MB, andere Größen vorhanden.]
\end{styleTextkrperMaster}

\section{5. Bechers Programmierversuch}
\begin{styleTextkrperMaster}
Zum Lebenswerk von Johann Joachim Becher (1635-1682) gehört die Entwicklung einer Interlingua als Code zur Entschlüsselung fremder Sprachen. Bechers Wirken als Chemiker, Techniker und Politikberater, seine Schriften über Handel und Warenexport und die Gründung einer Art Technologiezentrum für verschiedene Handelszweige verdeutlichen den gesellschaftlichen Kontext seiner Idee. Sprengler (2014) bezeichnet ihn als ersten Volkswirt, der als Merkantilist die Produktion und den Export von Waren fördern wollte. Er sei selbst kein Kaufmann gewesen, sondern habe sich theoretisch mit den Voraussetzungen für den Verkauf von Gütern in andere Länder beschäftigt (Sprengler 2014). Becher selbst sah sein Werk als Beitrag zur Völkerverständigung. Seine Methode zur Kommunikation in anderen Sprachen versah er mit dem Untertitel „Eine geheimschriftliche Erfindung, bisher unerhört, womit jeder beim Lesen in seiner eigenen Sprache verschiedene, ja sogar alle Sprachen, durch eintägiges Einarbeiten erklären und verstehen kann“ (Becher 1962). 
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Sein Werk \textit{Allgemeine Verschlüsselung der Sprachen} aus dem Jahre 1661 wird heute als der erste Programmierversuch bezeichnet. Becher kannte Kirchers Entwurf einer Plansprache und entwarf ein Sprachsystem mit über zehntausend Wörtern, die er in einem erweiterbaren Indexverzeichnis festhielt. Die Zahlencodes wurden als Punkte und Striche in „Schlüsseln“ (siehe Abbildung 4 und 5) graphisch umgesetzt. Abbildung 4 zeigt das Grundprinzip zur Entschlüsselung, dem beim Lesen dieser Zeichen gefolgt werden muss:
\end{styleTextkrperMaster}

\begin{styleZitatMaster}
„Wenn du im Raum von A oder B, C, D ein kleines Strichlein in waagerechter Richtung erblickst, so bedeutet dies fünf. Einzelne Pünktchen bei A bezeichnen jedesmal eine Einheit, so oft sie gesetzt sind. Senkrechte Striche in B erfordern, daß du soviele Zehnereinheiten zählst, wie Striche da sind, in C soviele Hunderteinheiten wie Striche, in D soviele Tausender wie Striche vorhanden sind.“ (Becher 1962, 31)
\end{styleZitatMaster}

\begin{styleTextkrperMaster}
In den Bereichen A, B, C und D (siehe Abbildung 4) werde ein Wort anhand des Index dargestellt. Der zweite Teil des Schlüssels in den Bereichen E, F, G, H und I zeige die „Flexion des Wortes“ (Becher 1962, 32). In den Bereichen L und K können Satzzeichen markiert und Pluszeichen ergänzt werden. So markiere z.~B. ein Pluszeichen die adverbiale Verwendung eines Wortes, drei Pluszeichen bedeuten hingegen, dass es sich um „eine reine Zahl“ handelt (Becher 1962, 32). Abbildung 5 ist der Abhandlung von Reinermann (2006) entnommen und veranschaulicht die Bechersche Methode an einem Beispielsatz. Aufgrund der Komplexität des entwickelten Zeichensystems wird Becher, trotzdem sich seine Methode aufgrund vieler praktischer Mängel nicht durchsetzen konnte, als ein Vordenker der automatischen Sprachübersetzung angesehen (vgl. Reinermann 2006).
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
[Hier \textbf{Abbildung 4 }einfügen: Abbildung4\_Becher\_Schlüsselprinzip.png. Scan aus Becher 1962 (s.~u.), Ausschnitt aus Seite 35, selbst ausgeschnitten und Helligkeit und Kontrast optimiert. Buch liegt bei mir.]
\end{styleTextkrperMaster}

\begin{styleStandard}
[Hier \textbf{Abbildung 5 }einfügen: Abbildung5\_Becher\_Beispiel\_Reinermann. Bild 14 entnommen aus Reinermann 2014, Seite 18 (\url{https://www.uni-speyer.de/fileadmin/Ehemalige/Reinermann/jjbheft22.pdf}),
\end{styleStandard}

\begin{styleStandard}
[(optional auch \textbf{Abbildung 6} einfügen\textbf{:} Abbildung6\_Becher\_Titelblatt\_1661. Scan aus Becher 1962 (s~u.), Seite 5. Bild ausgeschnitten und Kontrast optimiert, Buch liegt bei mir.)]
\end{styleStandard}

\section{6. Der Übergang zur Maschinellen Übersetzung}
\begin{styleTextkrperMaster}
Das 20. Jahrhundert markiert den Übergang zur Theorie und Praxis der Maschinellen Übersetzung, einem konzeptuell zwar untergeordneten, aber doch sehr starken und somit für sich selbst stehenden Feld. Zweifelsohne hat sich mit der Maschinellen Übersetzung ein Traum der alten Gelehrten erfüllt, denn sie selbst verbrachten viel Zeit damit, die Schriften unbekannter Sprache zu entschlüsseln, um deren Inhalt zu verstehen. Jede der hier vorgestellten Ideen für algorithmische Übersetzungsverfahren diente bestimmten gesellschaftlichem Zwecken und ist durch ihren philosophisch-weltanschaulichen Kontext geprägt.
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Mitte der 1930er Jahre entwickelten Georges Artsrouni und Peter Trojanskij unabhängig voneinander Übersetzungsmaschinen und meldeten dafür auch Patente an. Die beiden Ingenieure werden als Pioniere der Maschinellen Übersetzung bezeichnet. Die von ihnen entwickelten algorithmischen Verfahren wurden auf bilinguale Wortverzeichnisse angewandt und konnten einfache Wortfolgen übertragen. Mit Maschineller Übersetzung hatten diese Erfindungen nur bedingt etwas zu tun, da diese Ansätze die Komplexität menschlicher Sprache nicht annähernd abbildeten.
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Die in der Folge des berühmten Weaver-Memorandums (1949) entwickelten Ansätze nahmen in ihrer Mächtigkeit stetig zu. Sie werden heute üblicherweise in regelbasierte und datenbasierte Verfahren unterteilt. Blickt man aber auf die hier vorgestellten historischen Skizzen zurück, ließe sich durchaus eine andere Unterteilung vornehmen: Regelbasierte und statistische Ansätze könnte man demnach unter Verfahren der Dekodierung und Rekodierung fassen, während neuronale Ansätze mit häufig in sich mehrsprachigen Sprachmodellen der Idee einer Universalcode-Maschine durchaus nahekommen.
\end{styleTextkrperMaster}

\begin{styleTextkrperMaster}
Die Aufstellung der historischen Verfahrensskizzen für eine Algorithmische Übersetzung ist mehr als nur ein Zurückblicken auf die Anfänge. Neben dem Angebot einer alternativen Perspektive auf die Klassifikation heutiger Maschineller Übersetzungssysteme erinnert sie uns daran, wie alt und vielfältig der Traum von einer einfachen, berechenbaren Übersetzung zwischen Sprachen ist.
\end{styleTextkrperMaster}

\section[Bibliografie]{\textstyleHeadingiiChar{Bibliografie}}
\begin{styleBibliography}
Becher, Johann Joachim. 1962. Zur mechanischen Sprachübersetzung. Ein Programmierungsversuch aus dem Jahre 1661. Allgemeine Verschlüsselung der Sprachen (Character, pro Notitia Linguarum Universali) deutsch-lateinisch. Herausgegeben von Prof. Dr. Walter Georg Waffenschmidt. Veröffentlichungen der Wirtschaftshochschule Mannheim. Stuttgart: W. Kohlhammer.
\end{styleBibliography}

\begin{styleBibliography}
Bedürftig, Thomas, und Roman Murawski. 2015. Philosophie der Mathematik. 3. Aufl. Berlin, Boston: De Gruyter.
\end{styleBibliography}

\begin{styleBibliography}
Breger, Herbert. 2009. „Leibniz’ Binäres Zahlensystem Als Grundlage Der Computertechnologie“. In Jahrbuch Der Akademie Der Wissenschaften Zu Göttingen 2008, 385–91. Berlin: Walter de Gruyter GmbH \& Co. KG. https://doi.org/10.26015/adwdocs-289.
\end{styleBibliography}

\begin{styleBibliography}
Duda, Justine. 2016. „Die Anfänge moderner Computertechnik. Raimundus Lullus - Leben und Werk“. Kompetenzzentrum für elektronische Erschließungs- und Publikationsverfahren in den Geisteswissenschaften der Universität Trie. 2016. https://dhmuseum.uni-trier.de/node/354.
\end{styleBibliography}

\begin{styleBibliography}
DuPont, Quinn. 2018. „The Cryptological Origins of Machine Translation, from al-Kindi to Weaver“. amodern 8. http://amodern.net/article/cryptological-origins-machine-translation/.
\end{styleBibliography}

\begin{styleBibliography}
Leibniz, Gottfried Wilhelm. 1890. Die philosophischen Schriften. Herausgegeben von Carl Immanuel Gerhardt. Bd. 7. Berlin: Weidmann.
\end{styleBibliography}

\begin{styleBibliography}
———. 1960. Fragmente zur Logik. Herausgegeben von Franz Schmidt. Berlin: Akademie-Verlag.
\end{styleBibliography}

\begin{styleBibliography}
Martiny, Jonas. 2018. „Ramón Llulls Wahrheitsmaschine“. 2018. https://www.jonasmartiny.com/2018/05/26/ramon-llulls-wahrheitsmaschine/.
\end{styleBibliography}

\begin{styleBibliography}
Pring-Mill, Robert D. F. 2001. Der Mikrokosmos Ramon Llulls: eine Einführung in das mittelalterliche Weltbild. Übersetzt von Ulli Roth. Bd. 9. Clavis pansophiae. Stuttgart-Bad Cannstatt: Frommann-Holzboog.
\end{styleBibliography}

\begin{styleBibliography}
Reinermann, Heinrich. 2006. „Automatische Sprachübersetzung anno 1661 mit Johann Joachim Becher“. In Zwei Tüftler aus der Pfalz: J.J. Becher und H. Hollerith, 5–47. Schriftenreihe der Johann Joachim Becher-Gesellschaft e.V 22. Speyer: Johann-Joachim-Becher-Gesellschaft zu Speyer: https://www.uni-speyer.de/fileadmin/Ehemalige/Reinermann/jjbheft22.pdf.
\end{styleBibliography}

\begin{styleBibliography}
Schmeh, Klaus. 2006. Codeknacker gegen Codemacher. Die faszinierende Geschichte der Verschlüsselung. Wiesbaden: Springer.
\end{styleBibliography}

\begin{styleBibliography}
Singh, Simon. 2001. Geheime Botschaften: die Kunst der Verschlüsselung von der Antike bis in die Zeiten des Internet. München: Hanser.
\end{styleBibliography}

\begin{styleBibliography}
Sprengler, Hans-Joachim. 2014. „Johann Joachim Becher - der erste Volkswirt“. In J. J. Becher und die Gegenwart[202F?]: Hans-Joachim Spengler zum 70. Geburtstag, herausgegeben von Carl Böhret, 32:31–33. Schriftenreihe der Johann-Joachim-Becher-Gesellschaft zu Speyer. Speyer: Johann-Joachim-Becher-Gesellschaft. https://rpb.lbz-rlp.de/107t160153.
\end{styleBibliography}

\begin{styleBibliography}
Stein, Daniel. 2009. „Maschinelle Übersetzung – Ein Überblick“. Journal for Language Technology and Computational Linguistics 24 (3): 5–18. https://doi.org/10.21248/jlcl.24.2009.119.
\end{styleBibliography}

\begin{styleBibliography}
Strasser, Gerhard Friedrich. 1988. Lingua universalis: Kryptologie und Theorie der Universalsprachen im 16. und 17. Jahrhundert. Wolfenbütteler Forschungen. Wiesbaden: Harrassowitz. http://d-nb.info/880432756/04.
\end{styleBibliography}

\begin{styleBibliography}
Strick, Heinz Klaus. 2009. „Al Kindi (800–870):[202F?]»Der erste Philosoph der arabischen Welt«“. Spektrum der Wissenschaft. Der mathematische Monatskalender, 2009. https://www.spektrum.de/wissen/abu-yusuf-yaqub-ibn-ishaq-al-sabbah-al-kindi-800-870/1001728.
\end{styleBibliography}

\begin{styleBibliography}
Weaver, Warren. 1949. „Translation“. In Proceedings of the Conference on Mechanical Translation. Massachusetts Institute of Technology. https://aclanthology.org/1952.earlymt-1.1.
\end{styleBibliography}

\begin{styleBibliography}
Wieber, Reinhard. 1977. „Kryptographie bei Qalqašand\=\i“. Zeitschrift der Deutschen Morgenländischen Gesellschaft Supplement IV (XX. Deutscher Orientalistentag): 257–60. https://menadoc.bibliothek.uni-halle.de/dmg/periodical/pageview/127051.
\end{styleBibliography}

\begin{styleBibliography}
Zotter, Hans. 2004. „Parallele Modelle von Wissenssicherung und Ordnung“. In Wissenssicherung, Wissensordnung und Wissensverarbeitung: das europäische Modell der Enzyklopädien, herausgegeben von Theo Stammen und Wolfgang E. J. Weber, 25–37. Colloquia Augustana 18. Berlin: Akademie Verlag. https://doi.org/10.1524/9783050055824.
\end{styleBibliography}

\begin{styleStandard}

\end{styleStandard}
\end{document}
