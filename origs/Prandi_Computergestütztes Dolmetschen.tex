% This file was converted to LaTeX by Writer2LaTeX ver. 1.4
% see http://writer2latex.sourceforge.net for more info
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath}
\usepackage{amssymb,amsfonts,textcomp}
\usepackage{array}
\usepackage{hhline}
\usepackage{hyperref}
\hypersetup{colorlinks=true, linkcolor=blue, citecolor=blue, filecolor=blue, urlcolor=blue}
\usepackage{graphicx}
% footnotes configuration
\makeatletter
\renewcommand\thefootnote{\arabic{footnote}}
\makeatother
\newcommand\textsubscript[1]{\ensuremath{{}_{\text{#1}}}}
% Text styles
\newcommand\textstyleListLabelcxlvi[1]{#1}
\newcommand\textstyleListLabelcxlvii[1]{#1}
\newcommand\textstyleListLabelcxlviii[1]{#1}
\newcommand\textstyleListLabelcxlix[1]{#1}
% Headings and outline numbering
\makeatletter
\renewcommand\section{\@startsection{section}{1}{0.25in}{0.1665in}{0.0835in}{\normalfont\normalsize\fontsize{18pt}{21.6pt}\selectfont\rmfamily\bfseries\raggedright}}
\renewcommand\subsection{\@startsection{subsection}{2}{0.25in}{0.222in}{0.0835in}{\normalfont\normalsize\fontsize{16pt}{19.2pt}\selectfont\rmfamily\bfseries\raggedright}}
\renewcommand\@seccntformat[1]{\csname @textstyle#1\endcsname{\csname the#1\endcsname}\csname @distance#1\endcsname}
\setcounter{secnumdepth}{0}
\newcommand\@distancesection{}
\newcommand\@textstylesection[1]{#1}
\newcommand\@distancesubsection{}
\newcommand\@textstylesubsection[1]{#1}
\makeatother
\raggedbottom
% Paragraph styles
\renewcommand\familydefault{\rmdefault}
\newenvironment{styleStandard}{\setlength\leftskip{0cm}\setlength\rightskip{0cm plus 1fil}\setlength\parindent{0cm}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{12pt}{14.4pt}\selectfont\writerlistlabel\ignorespaces}{\unskip\vspace{0.111in plus 0.0111in}\par}
\newenvironment{stylelsAbstract}{\setlength\leftskip{0.5in}\setlength\rightskip{0.5in}\setlength\parindent{0in}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{12pt}{14.4pt}\selectfont\itshape\writerlistlabel\ignorespaces}{\unskip\vspace{0.111in plus 0.0111in}\par}
\newenvironment{styleTacubaBody}{\renewcommand\baselinestretch{1.25}\setlength\leftskip{0cm}\setlength\rightskip{0cm plus 1fil}\setlength\parindent{0cm}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{12pt}{14.4pt}\selectfont\writerlistlabel\ignorespaces}{\unskip\vspace{0in plus 1pt}\par}
\newenvironment{stylelsBulletList}{\renewcommand\baselinestretch{1.0}\setlength\leftskip{0cm}\setlength\rightskip{0cm plus 1fil}\setlength\parindent{0cm}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{12pt}{14.4pt}\selectfont\writerlistlabel\ignorespaces}{\unskip\vspace{0.111in plus 0.0111in}\par}
\newenvironment{styleListParagraph}{\setlength\leftskip{0.5in}\setlength\rightskip{0in plus 1fil}\setlength\parindent{0in}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{12pt}{14.4pt}\selectfont\writerlistlabel\ignorespaces}{\unskip\vspace{0.111in plus 0.0111in}\par}
\newenvironment{styleBibliography}{\setlength\leftskip{0.5in}\setlength\rightskip{0in plus 1fil}\setlength\parindent{-0.5in}\setlength\parfillskip{0pt plus 1fil}\setlength\parskip{0in plus 1pt}\writerlistparindent\writerlistleftskip\leavevmode\normalfont\normalsize\fontsize{12pt}{14.4pt}\selectfont\writerlistlabel\ignorespaces}{\unskip\vspace{0in plus 1pt}\par}
% List styles
\newcommand\writerlistleftskip{}
\newcommand\writerlistparindent{}
\newcommand\writerlistlabel{}
\newcommand\writerlistremovelabel{\aftergroup\let\aftergroup\writerlistparindent\aftergroup\relax\aftergroup\let\aftergroup\writerlistlabel\aftergroup\relax}
\newcounter{listWWNumxxvileveli}
\renewcommand\thelistWWNumxxvileveli{\arabic{listWWNumxxvileveli}}
\newcommand\labellistWWNumxxvileveli{\textstyleListLabelcxlvi{\thelistWWNumxxvileveli.}}
\newcommand\labellistWWNumxxvilevelii{\textstyleListLabelcxlvii{o}}
\newcommand\labellistWWNumxxvileveliii{\textstyleListLabelcxlviii{[F0A7?]}}
\newcommand\labellistWWNumxxvileveliv{\textstyleListLabelcxlix{[F0B7?]}}
\newenvironment{listWWNumxxvileveli}{\def\writerlistleftskip{\setlength\leftskip{0.5in}}\def\writerlistparindent{}\def\writerlistlabel{}\def\item{\def\writerlistparindent{\setlength\parindent{-0.25in}}\def\writerlistlabel{\stepcounter{listWWNumxxvileveli}\makebox[0cm][l]{\labellistWWNumxxvileveli}\hspace{-0.635cm}\writerlistremovelabel}}}{}
\newenvironment{listWWNumxxvilevelii}{\def\writerlistleftskip{\setlength\leftskip{1in}}\def\writerlistparindent{}\def\writerlistlabel{}\def\item{\def\writerlistparindent{\setlength\parindent{-0.25in}}\def\writerlistlabel{\makebox[0cm][l]{\labellistWWNumxxvilevelii}\hspace{-1.905cm}\writerlistremovelabel}}}{}
\newenvironment{listWWNumxxvileveliii}{\def\writerlistleftskip{\setlength\leftskip{1.5in}}\def\writerlistparindent{}\def\writerlistlabel{}\def\item{\def\writerlistparindent{\setlength\parindent{-0.25in}}\def\writerlistlabel{\makebox[0cm][l]{\labellistWWNumxxvileveliii}\hspace{-3.175cm}\writerlistremovelabel}}}{}
\newenvironment{listWWNumxxvileveliv}{\def\writerlistleftskip{\setlength\leftskip{2in}}\def\writerlistparindent{}\def\writerlistlabel{}\def\item{\def\writerlistparindent{\setlength\parindent{-0.25in}}\def\writerlistlabel{\makebox[0cm][l]{\labellistWWNumxxvileveliv}\hspace{-4.4449997cm}\writerlistremovelabel}}}{}
\title{}
\author{Bianca}
\date{2024-12-24}
\begin{document}
\title{Computergestütztes Dolmetschen}
\maketitle

\begin{styleStandard}
Bianca Prandi
\end{styleStandard}

\begin{styleStandard}
Leopold-Franzens-Universität Innsbruck
\end{styleStandard}

\begin{stylelsAbstract}
Das Kapitel bietet eine umfassende Einführung in das computergestützte Dolmetschen und die neueste Forschung zu unterstützenden Technologien für Dolmetscher*innen. Im ersten Teil des Kapitels wird die Entwicklungsgeschichte von CAI-Tools präsentiert. Es werden zudem die neuesten Entwicklungen im Bereich computergestützten Dolmetschens sowie der aktuelle Stand der Automation in den verschiedenen Dolmetschphasen. Das zweite Teil des Kapitels widmet sich der Forschung im Bereich des computergestützten Dolmetschens. Es werden die aktuellen Forschungsfragen, -methoden und -ergebnisse präsentiert. Das Ziel besteht darin, den aktuellen Wissensstand zu CAI-Tools zu erfassen und Forschungslücken zu identifizieren, um Lesenden eine Orientierungshilfe anzubieten. Das Kapitel endet mit Überlegungen zu den möglichen zukünftigen Entwicklungen in diesem Bereich.
\end{stylelsAbstract}

\section[Einleitung]{Einleitung}
\begin{styleTacubaBody}
Die zunehmende Technologisierung, die auch den Dolmetschberuf betrifft, wirft eine Vielzahl von Fragen bezüglich des Potenzials auf, die Technologie und insbesondere die künstliche Intelligenz (KI) zugunsten von DolmetscherInnen einzusetzen. Der vorliegende Beitrag zielt darauf ab, Lesenden einen kritischen Überblick über unterstützende Technologien für das Dolmetschen zu liefern. Er kann somit als Orientierungshilfe sowohl für die Praxis als auch für die Forschung und die Lehre betrachtet werden.
\end{styleTacubaBody}

\begin{styleTacubaBody}
Dolmetschtechnologie bewegt sich auf einem Kontinuum, das von \textit{Distance} zu \textit{Assistance} (Pöchhacker \& Liu 2024) bis hin zur Automatisierung reicht. Das computergestützte Dolmetschen bezeichnet den Einsatz von Hardware und Software zur Voll- oder Teilautomatisierung verschiedener Aufgaben im Arbeitsablauf der DolmetscherInnen. Das Endprodukt, die Verdolmetschung, wird jedoch weiterhin vom Dolmetschenden geliefert (Will 2020: 47).
\end{styleTacubaBody}

\begin{styleTacubaBody}
In Anlehnung an den Bereich des Übersetzens wurde bereits zu Beginn der 1990er Jahre die Suche nach Möglichkeiten initiiert, die Arbeitsabläufe von DolmetscherInnen durch Technologie zu unterstützen. Unterstützende Dolmetschtechnologie unterscheidet sich von vermittelnder Technologie (Braun 2020) dadurch, dass sie nicht das Setting beeinflusst, in dem Dolmetschleistungen erbracht werden. Im Gegensatz dazu können computergestützte Dolmetschtools (im engl. \textit{Computer-Assisted Interpreting }bzw. CAI-Tools) als prozessorientierte Technologie bezeichnet werden (Fantinuoli 2018), da sie darauf abzielen, die Teilprozesse beim Dolmetschen zu optimieren. Zu diesem Zweck werden unter anderem auch diejenigen Technologien eingesetzt, die zur Teil- oder Vollautomatisierung des Dolmetschprozesses beitragen können. Dies veranschaulicht, dass die drei Unterkategorien der Unterstützung, Vermittlung und Automatisierung in der Tat zunehmend miteinander verbunden sind. Exemplarisch hierfür ist die Integration unterstützender Funktionen durch den Einsatz von KI in Plattformen für das Ferndolmetschen sowie die Entstehung hybrider Dolmetschformen durch die Integration automatisierender Technologien in traditionelle Dolmetschprozesse wie etwa bei Sim-Consec (Orlando 2014) oder SightConsec (Ünlü 2023a).
\end{styleTacubaBody}

\begin{styleTacubaBody}
DolmetscherInnen steht eine Reihe von Technologien zur Verfügung, die als Hilfestellung eingesetzt werden kann. Hierzu zählen sowohl Hardware (wie beispielsweise Tablets für das computergestützte Konsekutivdolmetschen) als auch Software unterschiedlicher Art. Letztere umfasst zum einen allgemein verfügbare Programme wie z.B. Microsoft Word oder Excel, zum anderen dolmetschspezifische Programme wie etwa InterpretBank (Fantinuoli 2016) oder Interpreters’ Help.\footnote{\ \url{https://interpretershelp.com/} (Accessed 2024-12-23.)} Schließlich sind auch Programme, die auf generativer KI basieren (wie ChatGPT oder Gemini) Teil dieser Entwicklung. Angesichts dieser Tatsache befürworten manche AutorInnen eine breite Definition von CAI-Tools, die alle Lösungen umfasst, die DolmetscherInnen als Unterstützung verwenden können (vgl. Bowker 2022). In anderen Fällen wird eine engere Definition von CAI-Tools bevorzugt (vgl. z.B. Fantinuoli 2018; Prandi 2023), die nur diejenigen Softwareprogramme erfasst, die speziell für DolmetscherInnen entwickelt wurden. Allgemein können als CAI-Tools alle Lösungen bezeichnet werden, die den Dolmetschprozess beeinflussen und darauf abzielen, den kognitiven Aufwand von DolmetscherInnen zu reduzieren. Je nachdem, ob CAI-Tools während des Dolmetschens, nur vor oder nach der Verdolmetschung oder in allen Phasen eines Dolmetscheinsatzes Verwendung finden, wird unter primären, sekundären und integrierten CAI-Tools unterschieden (Will 2020).
\end{styleTacubaBody}

\begin{styleTacubaBody}
Um das Potential unterstützender Technologien für das computergestützte Dolmetschen zu veranschaulichen, liefert § \ref{bkm:Ref181546739}\ einen Überblick über die Technologie. Die Übersicht der Forschungsfragen, -methoden und -ergebnisse in § \ref{bkm:Ref181546760}\ soll die aktuellen Grenzen und Möglichkeiten von CAI-Tools erläutern. § \ref{bkm:Ref181546783}\ fasst den Inhalt des Kapitels zusammen und präsentiert einige Überlegungen zu den potenziellen zukünftigen Entwicklungen im Bereich des computergestützten Dolmetschens.
\end{styleTacubaBody}

\section[Technologie]{Technologie}
\label{bkm:Ref181546739}\subsection[Aktueller Stand der Automation]{Aktueller Stand der Automation}
\begin{styleStandard}
In der Automation menschlicher Tätigkeiten sind verschiedene Phasen erkennbar. Fantinuoli (2018) differenziert in diesem Zusammenhang zwischen vier Phasen, die sich von der reinen menschlichen Tätigkeit über die maschinengestützte Tätigkeit bis hin zur menschunterstützten maschinellen Tätigkeit und schließlich zur vollständig automatisierten Tätigkeit erstrecken. Diese vier Phasen decken sich in etwa mit der von Parasumaran et al. (2000) vorgeschlagenen Automationsskala, wobei die oberen Stufen durch eine verstärkte Autonomie der Maschine gekennzeichnet sind. Wie bei allen Fällen der Mensch-Maschinen-Interaktion können auch beim computergestützten Dolmetschen unterschiedliche Grade der Automation identifiziert werden. Gemäß dem Automationsgrad lassen sich bis zu vier Generationen von CAI-Tools identifizieren (Prandi 2025). CAI-Tools der ersten Generation bieten einfache Funktionen für die Verwaltung und Erstellung von Terminologiesammlungen, während Tools der zweiten Generation zusätzliche Funktionen zur Bearbeitung von Vorbereitungsunterlagen, Terminologieextraktion und Memorierung der Termini bereithalten. Tools der dritten Generation zeichnen sich durch einen hohen Automationsgrad aus, wobei auch ‚traditionelle‘ Arbeitsweisen unterstützt werden. Tools der vierten Generation sind in Plattformen für das simultane Ferndolmetschen integriert und zielen auf eine möglichst vollständige Automation verschiedener Arbeitsschritte ab. Im Weiteren werden die konkreten Möglichkeiten der Unterstützung durch Technologie und insbesondere KI für die verschiedenen Phasen eines Dolmetscheinsatzes erläutert.
\end{styleStandard}

\subsection[Vor{}- und Nachbereitungsphase]{Vor- und Nachbereitungsphase}
\begin{stylelsBulletList}
In der Vor- und Nachbereitungsphase liegt der Fokus der technologischen Unterstützung vorwiegend auf der Terminologiearbeit. In den Phasen vor und nach dem Prozess (vgl. Kalina 2005) können DolmetscherInnen Technologie einsetzen, um Glossare zu erstellen und Terminologie zu lernen. Eine wichtige Phase in der Glossarerstellung kann das Zusammenstellen von Korpora nach den Grundsätzen der \textit{Corpus-Driven Interpreters’ Preparation }(Fantinuoli 2017a) sein. Unter der Prämisse einer Informationskluft zwischen ExpertInnen (Kundschaft, Publikum) und Laien (DolmetscherInnen) sowie angesichts des Zeitdrucks kann die Korpusarbeit eine nützliche Ressource darstellen. DolmetscherInnen können Tools wie SketchEngine (Kilgarriff et al. 2014) oder \#LancsBox X (Brezina \& Platt 2024) verwenden, um auf Stichwörtern (\textit{Seeds}) basierend Texte zu sammeln, die für einen bestimmten Fachbereich von Relevanz sind. Ausgehend von diesen Sammlungen können Terminologielisten erstellt werden, entweder durch eine manuelle oder eine automatische Terminologieextraktion oder beides. Zudem können CAI-Tools verwendet werden, um die Glossare in einer einzelnen Datenbank zu verwalten. Durch die Integration von KI-basierten Funktionen kann die Glossarerstellung komplett automatisiert werden. Es besteht beispielsweise die Möglichkeit, aus Webseiten oder Dokumenten Terminologie automatisch zu extrahieren und die Termini durch neuronale maschinelle Übersetzung (NMÜ) zu übersetzen. DolmetscherInnen können diesen Glossarentwurf weiter verfeinern und die automatischen Ergebnisse prüfen.
\end{stylelsBulletList}

\begin{stylelsBulletList}
Angesichts der rasanten Entwicklungen im Bereich der generativen KI ist es plausibel, Large Language Models (LLMs) auch in der Vorbereitungsphase zu implementieren. LLMs sind sowohl als eigenständige Lösungen als auch als Integration in CAI-Tools verfügbar. Im letzteren Fall können LLMs beispielsweise dazu beitragen, mehr Kontext für die Terminologieextraktion bereitzustellen (siehe z.B. InterpretBank Version 9.40). Schnittstellen wie ChatGPT oder Gemini ermöglichen die Interaktion mit LLMs, die durch Anleitungen in natürlicher Sprache (\textit{Prompts}) aufgefordert werden können, um verschiedene Aufgaben zu erledigen. Hierzu zählen die Erstellung von Glossarentwürfen, die Terminologieextraktion, die Systematisierung von Termlisten, das Brainstorming von Ideen zum Veranstaltungsthema oder zu einsatzrelevanten Faktoren, die Zusammenfassung und Übersetzung von Dokumenten und viel mehr (bei LLMs ist die Übersetzung sehr eng konzipiert, siehe Pym \& Hao 2024: 7). Darüber hinaus können die Textgenerierungsfähigkeiten von LLMs dazu genutzt werden, um Reden zu generieren, die als Übungsmaterialien sowohl zur Vorbereitung auf einen Dolmetscheinsatz als auch im Training dienen können (vgl. z.B. das Projekt „InterpreTutor{\textquotedbl}, Ünlü 2023b). 
\end{stylelsBulletList}

\begin{stylelsBulletList}
Einige CAI-Tools (InterpretBank und Interpreters’ Help) bieten Funktionen für das computergestützte Erlernen der Terminologie an. Glossare werden in digitale Karteikarten umgewandelt, durch die NutzerInnen manuell oder automatisch navigieren. Die Programme speichern den Fortschritt und ermöglichen es, die Übung auf die Fehler zu intensivieren. InterpretBank ermöglicht zudem die Präsentation der Karteikarten im Audioformat mittels Sprachsynthese, sodass DolmetscherInnen sich auf den akustischen Input fokussieren können.
\end{stylelsBulletList}

\begin{stylelsBulletList}
Die zuvor genannten Einsatzmöglichkeiten von KI sind selbstverständlich auch für die Nachbereitungsphase von Relevanz. In diesem Kontext sind insbesondere die Aufgaben der Terminologiearbeit zu nennen. Dies umfasst beispielsweise die Ergänzung eigener Terminologieressourcen durch Termini und Fachausdrücke, die sich während des Einsatzes als relevant erwiesen haben und in den Vorbereitungsglossaren nicht berücksichtigt wurden. Darüber hinaus sind weitere Anwendungsfälle in der Reflektion der eigenen Arbeit im Umgang mit CAI-Tools zu berücksichtigen. Im Falle der Verwendung von CAI-Tools zum Nachschlagen von Terminologie in eigenen Glossaren oder der Unterstützung durch automatische Spracherkennung (ASE, siehe § \ref{bkm:Ref182486219}) kann das eigene Suchverhalten analysiert werden, um Schlussfolgerungen für die Interaktion mit Technologie als Unterstützung zu ziehen und die eigenen Strategien zu optimieren. Zu diesem Zweck können Log-Dateien oder Videoaufnahmen untersucht werden. Ferner wäre es denkbar, LLMs zur Evaluation der eigenen Dolmetschleistungen einzusetzen.
\end{stylelsBulletList}

\subsection[Dolmetschphase]{Dolmetschphase}
\label{bkm:Ref182486219}\begin{styleStandard}
Die Terminologiearbeit findet beim Dolmetschen kontinuierlich statt, sodass auch während des Dolmetschens und insbesondere in der Peri-Prozess-Phase (Kalina 2005) Glossare vervollständigt und Termini ad-hoc hinzugefügt werden können.
\end{styleStandard}

\begin{styleStandard}
Der Einsatz unterstützender Technologie in der Dolmetschphase betrifft allerdings vor allem das manuelle oder automatische Nachschlagen von Terminologie in CAI-Tools sowie die Möglichkeit, weitere \textit{Problem Triggers} (Gile 2009) wie Zahlen und \textit{Named Entities }(Namen von Organisationen, Ortsangaben, Eigennamen) durch Spracherkennung automatisch identifizieren und anzeigen zu lassen. Darüber hinaus können automatisch, in Echtzeit generierte Untertitel in der Ausgangs- oder Zielsprache von DolmetscherInnen als Hilfestellung verwendet werden. Einige CAI-Tools bieten eine ASE-Funktion an (vgl. Hansen-Schirra 2012; Fantinuoli 2017b), die das Gesagte transkribiert und durch einen entsprechenden Algorithmus \textit{Problem Triggers }erkennt. Im Falle der Zahlen werden diese auf dem Bildschirm angezeigt, mit oder ohne zusätzliche Informationen wie z.B. Größenordnung, Zeitangaben oder Maßeinheit. Automatisch erkannte Terminologie kann entweder mit den Einträgen in den von den DolmetscherInnen erstellten und validierten Glossaren verglichen und mit entsprechender Benennung in der Zielsprache angezeigt, oder automatisch übersetzt und eingeblendet werden (Fantinuoli et al. 2022). Zudem besteht die Möglichkeit, das Transkript einzublenden, [Warning: Draw object ignored]um den DolmetscherInnen zusätzlichen Kontext anzubieten.
\end{styleStandard}

\begin{center}
 [Warning: Image ignored] % Unhandled or unsupported graphics:
%\includegraphics[width=5.3681in,height=3.2291in,width=\textwidth]{PrandiComputergesttztesDolmetschen-img001.jpg}

\end{center}
\begin{styleStandard}
Derartige Einsatzmöglichkeiten sind nicht nur beim Simultandolmetschen, sondern auch beim Konsekutivdolmetschen vorstellbar. Im Rahmen von Experimenten im Konsekutivmodus wurde die Nutzung von ASE und/oder \textit{Respeaking} als Ergänzung oder Ersatz für traditionelle Notizen erörtert. Das generierte Transkript kann anschließend mittels NMÜ übersetzt werden (Ünlü 2023a; Chen \& Kruger 2023). So können sowohl die Rezeptions- als auch die Wiedergabephase partiell oder vollständig automatisiert werden. Bei der Wiedergabe der Rede in der Zielsprache ist es daher denkbar, dass DolmetscherInnen eine Art ‚Live-Post-Editing‘ durchführen, indem sie die automatisch generierte Übersetzung korrigieren und ergänzen, oder sie als zusätzliche Unterstützung zuziehen. Das Resultat ist ein neuer hybrider Dolmetschmodus, der als SightConsec oder CACI (\textit{Computer-Assisted Consecutive }Interpreting) bezeichnet werden kann. Darüber hinaus sind teilweise automatisierte Workflows möglich, bei denen nur Phase I (Rezeption) oder nur Phase 2 (Wiedergabe) durch KI unterstützt werden. Letztere wurde bereits erfolgreich getestet, beispielsweise beim Einsatz von Smartpens für den SimConsec-Modus (vgl. Orlando 2014).
\end{styleStandard}

\begin{styleStandard}
Abbildung 1\ gibt einen Überblick über die aktuellen Möglichkeiten des Einsatzes von KI in den verschiedenen Dolmetschphasen.
\end{styleStandard}

\section[Forschung]{Forschung}
\label{bkm:Ref181546760}\subsection[Forschungsfragen]{Forschungsfragen}
\label{bkm:Ref185868026}\begin{styleStandard}
Im Zuge der signifikanten Fortschritte in der KI sowie der vielfältigen Möglichkeiten der Automation beim Dolmetschen hat die Forschung im Bereich des computergestützten Dolmetschens in den vergangenen Jahren einen Aufwind erfahren. Neben Publikationen, die sich mit den theoretischen Grundlagen des computergestützten Dolmetschens beschäftigen (vgl. z. B. Rütten 2007; Stoll 2009; Will 2020), widmet sich die Forschung aktuell der empirischen Untersuchung von Fragen, die sich aus den Hauptzielen hinter der Entwicklung von CAI-Tools ableiten lassen: die kognitive Entlastung von DolmetscherInnen und die Verbesserung der Dolmetschqualität. Die leitenden Forschungsfragen lassen sich wie folgt subsumieren:
\end{styleStandard}


\setcounter{listWWNumxxvileveli}{0}
\begin{listWWNumxxvileveli}
\item 
\begin{styleListParagraph}
Inwiefern beeinflussen CAI-Tools die kognitiven Prozesse von DolmetscherInnen?
\end{styleListParagraph}
\item 
\begin{styleListParagraph}
Welche Auswirkungen hat der Einsatz von CAI-Tools auf die Dolmetschleistung?
\end{styleListParagraph}
\item 
\begin{styleListParagraph}
Wie gut ist die Systemleistung von CAI-Tools?
\end{styleListParagraph}
\end{listWWNumxxvileveli}
\begin{styleStandard}
Im Bereich (1) wurden Studien durchgeführt, die darauf abzielen, die kognitive Belastung beim computergestützten Dolmetschen zu untersuchen, sowohl im Vergleich zum ‚traditionellen‘ Dolmetschen als auch im Hinblick auf die verschiedenen Möglichkeiten der Automation. Nur wenige Studien untersuchten den Einsatz von Technologie während der Vorbereitungsphase. Xu und Sharoff (2014) sowie Xu (2018) untersuchten die Auswirkungen der korpusbasierten Vorbereitung auf die Terminologiearbeit von Dolmetschstudierenden und testeten verschiedene Lösungen für die automatische Terminologieextraktion. Darüber hinaus wurde die Auswirkung der computergestützten Vorbereitung auf die Dolmetschphase erforscht. Die Mehrzahl der Studien, die sich überwiegend mit prozessorientierten Aspekten des computergestützten Dolmetschens beschäftigten, betraf jedoch die Dolmetschphase (siehe § \ref{bkm:Ref182486219}). Zu Beginn wurde die Frage untersucht, wie sich die Verwendung von CAI-Tools für das manuelle Nachschlagen von Fachterminologie auf die kognitive Belastung auswirkt. Dabei wurden traditionelle Glossare in Form von Word-, Exceltabellen oder PDFs sowie Papierglossare mit digitalen Glossaren in CAI-Tools verglichen (Biagini 2015; Prandi 2018). Die Möglichkeit der automatischen Spracherkennung von \textit{Problem Triggers} motivierte zusätzliche Studien in diesem Bereich. Dabei wurden sowohl simulierte ASE (Prandi 2023; Frittella 2023) als auch die echten ASE-Funktionen von CAI-Tools oder eigenständigen Lösungen analysiert (wie die Untertitelungsfunktion von YouTube, vgl. Wang \& Wang 2019; und Li \& Chmiel 2024). In einigen Studien (Prandi 2023; Li \& Chmiel 2024; Yuan \& Wang 2023) wurde zudem untersucht, wie sich die visuelle Aufmerksamkeit der DolmetscherInnen beim Einsatz von ASE verteilt. Ein interessanter Forschungsbereich liegt in der Überprüfung alternativer Workflows für das Konsekutivdolmetschen. Chen und Kruger (2023) analysierten die Auswirkungen von ASE durch \textit{Respeaking} als Alternative zu den Notizen sowie von NMÜ als zusätzliche Unterstützung für die Wiedergabephase auf die kognitive Belastung von Dolmetschstudierenden.
\end{styleStandard}

\begin{styleStandard}
Darüber hinaus finden sich in der Literatur Studien, die die kognitiven Implikationen des computergestützten Dolmetschens im Hinblick auf die Didaktik von CAI-Tools untersuchten. Die Didaktik des computergestützten Dolmetschens stellt einen Forschungsbereich dar, der bisher nur unzureichend erforscht ist. Eine Studie von Prandi (2015) analysierte den Umgang mit CAI-Tools von Studierenden, um erste Erkenntnisse für die Entwicklung von Unterrichtseinheiten zu gewinnen. Frittella (2024) beschäftigte sich in ihrer Doktorarbeit mit der Modellierung der Kompetenzen, die für einen erfolgreichen Umgang mit CAI-Tools während des Dolmetschens erforderlich sind.
\end{styleStandard}

\begin{styleStandard}
Bei Studien im Bereich (2) liegt der Fokus auf der Erforschung der Qualität des computergestützten Dolmetschens. Dabei werden einzelne Qualitätselemente des Dolmetschproduktes oder die Dolmetschqualität im Allgemeinen untersucht. 
\end{styleStandard}

\begin{styleStandard}
Die Mehrheit der produktorientierten Studien eruierte die Auswirkungen von ASE auf die Präzision von Zahlwörtern in der Verdolmetschung. Dabei wurde beispielsweise das Dolmetschen mit und ohne simulierte ASE für Zahlen untersucht (Desmet, Vandierendonck \& Defrancq 2018). Weitere Studien fokussierten sich auf die ASE-unterstützte Verdolmetschung von Zahlen im CAI-Tool InterpretBank (Defrancq \& Fantinuoli 2020; Pisani \& Fantinuoli 2021). Ein besonderer Schwerpunkt lag hierbei auf der Analyse der Fehler, die beim computergestützten Dolmetschen auftreten können (Frittella 2022).
\end{styleStandard}

\begin{styleStandard}
Der Fokus weiterer Studien lag auf der Ergründung der Forschungsfrage, ob die ASE von Fachterminologie den Präzisionsgrad von Termini in der Verdolmetschung erhöhen kann, auch im Vergleich zum Einsatz von traditionellen digitalen Glossaren (vgl. z.B. Van Cauwenberghe 2020; Prandi 2023).
\end{styleStandard}

\begin{styleStandard}
Es sei darauf hingewiesen, dass produktbezogene Studien in vielen Fällen auch eine prozessorientierte Komponente aufweisen, da produktbezogene Ergebnisse nützliche Hinweise auf die mit computergestütztem Dolmetschen einhergehende kognitive Belastung liefern können.
\end{styleStandard}

\begin{styleStandard}
Obwohl menschenbezogene Faktoren den erfolgreichen Einsatz unterstützender Dolmetschtechnologie beeinflussen können, sind sowohl der Prozess als auch das Produkt von der Systemleistung abhängig. In diesem Zusammenhang zeichnet sich ein zusätzlicher Forschungsbereich (3) ab, der sich mit den technischen und ergonomischen Aspekten der Tools beschäftigt. Im Hinblick auf die Verwendung von ASE als Unterstützung sind insbesondere zwei Faktoren relevant: Präzision/Recall und Latenz. Die Präzision und der Recall sollten bei einem ASE-System möglichst hoch und die Latenz möglichst gering sein, um den Nutzen für DolmetscherInnen zu maximieren und die erfolgreiche Integration der automatisch generierten Vorschläge in die Verdolmetschung zu gewährleisten. Einige Studien enthielten eine Auswertung der Systemleistung in Bezug auf Präzision und Recall (Defrancq \& Fantinuoli 2020; Fantinuoli et al. 2022) oder waren gänzlich der Auswertung der Systemleistung gewidmet, wie im Falle von Rodríguez et al. (2021), die das CAI-Tool Smarterp\&me auf die Prüfung stellten. Fantinuoli und Montecchio (2023) untersuchten die Frage, mit welcher Latenz DolmetscherInnen umgehen können, ohne dass diese eine negative Auswirkung auf die Verdolmetschung hat. Die Systemleistung von CAI-Tools kann außerdem im Hinblick auf die Dolmetschphase betrachtet werden. So untersuchten Fantinuoli et al. (2022) unter anderem die Qualität automatisch erstellter Glossare in KUDO Interpreter Assist. Gegenwärtig widmet sich eine neue Welle empirischer Untersuchungen den ergonomischen Aspekten von CAI-Tools bzw. CAI-Funktionen in RSI-Plattformen. Im Fokus der Untersuchungen steht die Ergründung der potenziellen Auswirkungen des Designs von CAI-Funktionen, insbesondere ASE, auf die Dolmetschleistung. Die in diesem Zusammenhang relevanten Wünsche von DolmetscherInnen bezüglich der Nutzeroberfläche solcher Lösungen wurden teilweise bereits erörtert (z.B. in Saeed et al. 2022; Frittella 2023).
\end{styleStandard}

\subsection[Forschungsmethoden]{Forschungsmethoden}
\begin{styleStandard}
Das computergestützte Dolmetschen kann als Beispiel für die Mensch-Maschinen-Interaktion betrachtet werden. Die Komplexität dieser Interaktion bedingt den Einsatz geeigneter Forschungsmethoden, die einerseits mit den Forschungsfragen aligniert sind, und andererseits diese Komplexität evident machen und erörtern können.
\end{styleStandard}

\begin{styleStandard}
Im Rahmen der Forschung zum computergestützten Dolmetschen werden unterschiedliche Methoden verwendet, um die kognitive Belastung und die Dolmetschqualität zu messen. Diese Methoden können leistungsbasiert, subjektiv und psychophysiologisch sein (siehe z.B. Seeber 2013 für eine Übersicht der Methoden zur Messung kognitiver Belastung).
\end{styleStandard}

\begin{styleStandard}
Leistungsbasierte Methoden finden in Studien Anwendung, die sich primär mit der Qualität des computergestützten Dolmetschens befassen, sowie in prozessorientierten Untersuchungen. Man geht davon aus, dass das Produkt Informationen über den zugrunde liegenden Prozessen liefern kann. In der CAI-Forschung wird die Qualität auf der Basis verschiedener Skalen gemessen. Dabei liegt der Fokus entweder auf einzelnen Qualitätselementen oder auf der Gesamtleistung von DolmetscherInnen. Studien, die sich auf die Präzision der Zahlen bei der Verwendung von ASE als Unterstützung fokussieren, zielen darauf ab, die Anzahl und Art von Fehlern zu quantifizieren (vgl. z.B. Defrancq \& Fantinuoli 2020; Pisani \& Fantinuoli 2021). Dabei wird die Schwierigkeit anerkannt, die zu untersuchende Einheit exakt zu definieren, da eine korrekte Wiedergabe des Zahlworts mit Sinnfehlern einhergehen kann (vgl. Frittella 2022). Auch bei Fachterminologie werden Skalen verwendet, die den Präzisionsgrad der Verdolmetschung widerspiegeln. Beispiele finden sich in Van Cauwenberghe (2020) und Prandi (2023). In einigen Studien wird daher der Fokus auf das gesamte Translat erweitert, weil davon ausgegangen wird, dass eine Reduzierung der kognitiven Belastung sich positiv auf die gesamte Dolmetschqualität auswirken kann. Chen und Kruger kombinieren beispielsweise die analytische Skala von Han (2018), die „information completeness, fluency of delivery, and target language quality“ misst (Chen \& Kruger 2024a: 386), mit einer Propositionenbasierten Skala (Chen 2020), um die Präzision der Verdolmetschungen näher zu untersuchen. Auch die Sprechflüssigkeit (\textit{Fluency}) ist ein Qualitätsindikator, der gleichzeitig eine indirekte Messung der kognitiven Belastung ermöglichen kann. Chen und Kruger (2023) operationalisierten Sprechflüssigkeit als die Anzahl von ungefüllten und gefüllten Pausen, die sie jeweils automatisch und manuell maßen. In ihrer Follow-Up-Studie (Chen \& Kruger 2024a) wurde die manuell gemessene Sprechflüssigkeit um die Aspekte Wiederholungen und Selbstkorrekturen (\textit{Repairs)} erweitert. Die automatische Messung lieferte außerdem Daten zur Dauer der Verdolmetschung und zur Redegeschwindigkeit in der Zielsprache. Auch Ünlü (2023a: 85) verwendete verschiedene Indikatoren, d.h. „overall frequency of disfluencies, false starts, \ frequency of filled pauses, filler words, whole-word repetitions, broken words, and incomplete phrases“.
\end{styleStandard}

\begin{styleStandard}
Da die persönliche Erfahrung von DolmetscherInnen eine entscheidende Rolle für die effektive Verwendung von CAI-Tools spielen und gleichzeitig zusätzliche Hinweise auf die erlebte kognitive Belastung liefern kann, enthalten die meisten Studien auch eine subjektive Messungskomponente. Zu den subjektiven Methoden in der CAI-Forschung zählen \textit{post-hoc} Fragebögen, Usability-Fragebögen, Interviews, Fokusgruppen sowie validierte Tools wie der NASA-TLX (Hart 2006). Fragebögen wurden beispielsweise von Desmet et al. (2018), Defrancq und Fantinuoli (2020) und Ünlü (2023a) verwendet, um die subjektive Erfahrung der StudienteilnehmerInnen zu erkundigen. Rodríguez et al. (2023) verwendeten Usability-Fragebögen basierend auf dem \textit{User Experience Questionnaire} von Laugwitz et al. (2008), um die Nutzererfahrung beim Ferndolmetschen mit ASE-Unterstützung bei unterschiedlichen Benutzeroberflächen zu erörtern. Interviews und Fokusgruppen sind in diesem Forschungsbereich ein seltenes verwendetes Mittel, das jedoch zusätzliche Faktoren beim Einsatz von CAI-Tools zutage fördern kann. So führten Wang \& Wang (2019), Frittella (2023) und Gieshoff et al. (2024) \textit{post-}hoc Interviews mit den StudienteilnehmerInnen durch, um Einblicke über deren Erfahrung mit unterstützender Technologie zu gewinnen. Fokusgruppen wurden in Usability-Studien sowohl \textit{pre- }als auch \textit{post-hoc }eingesetzt (Saeed et al. 2022; Frittella 2023), um die Bedürfnisse und Präferenzen von DolmetscherInnen bezüglich des Designs von Tools zu eruieren. Ein signifikanter Vorteil dieser Methode liegt in der Möglichkeit, die StudienteilnehmerInnen aktiv in die Entwicklung von Tools zu involvieren. Der NASA-TLX (Hart 2006) stellt ein validierter Fragebogen zur Messung der empfundenen kognitiven Belastung dar, welches sechs Dimensionen umfasst: mentale, physische und zeitliche Anforderungen, Leistung, Anstrengung und Frustration. Der NASA-TLX wurde von Li \& Chmiel (2024) und Chen \& Kruger (2024a) zusammen mit anderen objektiven Messungen der kognitiven Belastung eingesetzt. 
\end{styleStandard}

\begin{styleStandard}
Psychophysiologische Methoden zeichnen sich durch eine geringere Subjektivität und Sprachunabhängigkeit aus, was die Vergleichbarkeit der Studienergebnisse erhöht (Prandi 2023: 121–122). Allerdings können sie intrusiver als andere Methoden sein und wurden deshalb bisher seltener in der CAI-Forschung eingesetzt. Eyetracking wurde von Prandi (2023), Yuan und Wang (2023), Chen \& Kruger (2024b) und Li und Chmiel (2024) verwendet. Im Rahmen der Untersuchungen der kognitiven Belastung durch Eyetracking wurden sowohl fixationsbasierte Maße (Zeit zur ersten Fixation, durchschnittliche Fixationsdauer, Fixationszeit, Anzahl der Fixationen) als auch die Maße \textit{Dwell Time}, welche Aufschluss über die Aufmerksamkeitsverteilung der StudienteilnehmerInnen geben kann, herangezogen. Stimmenkorrelate und Elektroenzephalographie sind in diesem Forschungsbereich weniger verbreitete Methoden. Defrancq et al. (2024) testeten den Einsatz der durchschnittlichen Grundfrequenz (F\textsubscript{0}) als potenzieller Korrelat von kognitiver Belastung und \textit{Fatigue} beim computergestützten Dolmetschen. Obwohl keine Korrelation festgestellt werden konnte, scheint diese Methode für die Messung von kognitiver Belastung vielversprechend zu sein (vgl. Shao \& Defrancq 2024). In der Studie von Li \& Chmiel (2024) konnte die EEG-Maße Theta-Aktivität erfolgreich als Indikator für kognitive Belastung eingesetzt werden, da sie mit kognitiv herausfordernden Aufgaben, höherer Belastung des Arbeitsgedächtnisses und größerer geistiger Ermüdung korreliert (Li \& Chmiel 2024: 257–258). Die Autoren weisen jedoch darauf hin, dass bei EEG eine hohe experimentelle Kontrolle sowie eine sorgfältige Bereinigung der Daten aufgrund möglicher Artefakte beim Simultandolmetschen erforderlich sind.
\end{styleStandard}

\subsection[Forschungsergebnisse]{Forschungsergebnisse}
\begin{styleStandard}
Obwohl zahlreiche Fragen hinsichtlich der Auswirkungen des computergestützten Dolmetschens auf den Prozess und das Produkt derzeit noch ungeklärt sind, erlauben die \textit{bis dato} durchgeführten Untersuchungen die Gewinnung erster Erkenntnisse.
\end{styleStandard}

\begin{styleStandard}
Der Einsatz von ASE als Live-Unterstützung während des Dolmetschens scheint eine positive Auswirkung auf die kognitive Belastung von DolmetscherInnen zu haben (Prandi 2023). Die Daten aus dem NASA-TLX-Fragebogen weisen auf eine niedrigere zeitliche Anforderung hin, wenn keine ASE-Untertitel angeboten werden (Li \& Chmiel 2024: 266), was jedoch mit den Ergebnissen von Chen \& Kruger (2023; 2024a; 2024b) kollidiert, da sie niedrigeren \textit{Temporal Demand} bei CACI im Vergleich zum konventionellen Konsekutivdolmetschen feststellten. Zudem scheint CACI zu einer besseren empfundenen Leistung zu führen, während roher TLX, mentale Anstrengung, Effort und Frustration von der Sprachrichtung moduliert sind: Ein signifikanter Effekt von CACI wurde lediglich beim Dolmetschen aus der Muttersprache (Chinesisch) in die Fremdsprache (Englisch) beobachtet (Chen \& Kruger 2024b: 11).
\end{styleStandard}

\begin{styleStandard}
Die vorliegenden Untersuchungen zeigen bisher keine eindeutigen Ergebnisse bezüglich des Zusammenhangs zwischen der Genauigkeit automatisch generierter Untertitel und der kognitiven Belastung von DolmetscherInnen. Allerdings deuten aktuelle Studien darauf hin, dass 100-prozentig korrekte Untertitel zu einer niedrigeren kognitiven Belastung führen könnte (Li \& Chmiel 2024). Es ist daher noch zu früh, um die kognitive Belastung bei ASE als definitiv niedriger oder höher einzustufen im Vergleich zum traditionellen Dolmetschen. Weitere Studien sind erforderlich, um die Implikationen von Unstimmigkeiten bei automatisch generierten Vorschlägen zu identifizieren. Eine weitere offene Forschungsfrage betrifft das Leseverhalten von DolmetscherInnen bei durch ASE generierten Untertiteln und einzelnem Input für \textit{Problem Triggers}.
\end{styleStandard}

\begin{styleStandard}
Wenn ASE anstatt von manueller Suche nach Terminologie eingesetzt wird, scheint sie den Fokus auf die Hauptinputquelle (RednerIn) zu fördern. Werden jedoch vollständige Untertitel eingeblendet, so schauen DolmetscherInnen tendenziell mehr auf die Untertitel als auf RednerInnen im Vergleich zum Dolmetschen ohne Unterstützung. Dieser Unterschied lässt sich in der Maße \textit{Dwell Time} widerspiegeln (Li \& Chmiel 2024; Yuan \& Wang 2023). Die Genauigkeit der Untertitel scheint jedoch keinen Einfluss darauf zu haben (Li \& Chmiel 2024). Diese Ergebnisse beziehen sich auf das computergestützte Simultandolmetschen. Beim Konsekutivdolmetschen können Unterschiede zwischen der Rezeptionsphase und der Produktionsphase festgestellt werden. In der Rezeptionsphase scheint die Aufmerksamkeit für das durch Respeaking erzeugte Transkript geringer zu sein. Allerdings korrelierte in Chen \& Kruger (2024b) eine längere \textit{Dwell Time} mit besserer Respeaking-Qualität. In der Produktionsphase wurde dem maschinell übersetzten Text mehr Aufmerksamkeit geschenkt, was wiederum mit einer besseren Qualität in der Verdolmetschung korrelierte, jedoch nur beim Dolmetschen aus der Fremdsprache (ibid.).
\end{styleStandard}

\begin{styleStandard}
Der Einsatz von CAI-Tools, insbesondere von ASE, scheint sich positiv auf die Dolmetschqualität auszuwirken. Verschiedene Studien weisen auf eine höhere Genauigkeit in der Verdolmetschung von Zahlen beim Einsatz von ASE hin (Desmet, Vandierendonck \& Defrancq 2018; Defrancq \& Fantinuoli 2020; Pisani \& Fantinuoli 2021). Die gleiche Tendenz zeigt sich bei Termini (Prandi 2023; Van Cauwenberghe 2020; Gieshoff, Schuler \& Jahany 2024) und Eigennamen (Yuan \& Wang 2023). Auch bei Untertiteln konnten positive Effekte festgestellt werden. Li und Chmiel (2024) konstatierten, dass Untertitel mit einer Genauigkeit über 90\% die Präzision verbessern, während weniger präzise Untertitel zu einer weniger akkuraten Verdolmetschung führen, die in ihrer Studie jedoch akkurater als ohne ASE war. Es sei jedoch angemerkt, dass auch negative Effekte festzustellen sind, wenn der Fokus der Untersuchung erweitert wird. So weisen einige Studien darauf hin, dass DolmetscherInnen das Risiko eingehen, sich zu sehr auf automatische Inputs zu stützen und Fehler zu importieren oder Sinnfehler zu begehen (Frittella 2022). Zudem können Terminologievorschläge mit der Satzplanung interferieren, wie Gieshoff et al. in einer Studie über den Einsatz von Augmented-Reality-Brillen (AR) feststellten (2024: 21).
\end{styleStandard}

\begin{styleStandard}
Obwohl Studien zur Mensch-Maschinen-Interaktion beim computergestützten Dolmetschen bislang selten sind, lieferten sie bereits nützliche Erkenntnisse für die nutzerorientierte Entwicklung unterstützender Dolmetschtechnologie. Die vorliegenden Studien zeigen, dass DolmetscherInnen einen großen Wert auf Anpassungsmöglichkeiten an individuelle Bedürfnisse legen (Frittella 2023; Gieshoff, Schuler \& Jahany 2024). Darüber hinaus tragen Usability-Studien zur Klärung konkreter Fragen bezüglich einzelner Elemente der Nutzeroberfläche bei. So wird deutlich, dass DolmetscherInnen eine Präferenz für die Einblendung von Untertiteln und ASE-Vorschläge am unteren Rand des Bildschirmes haben (Saeed et al. 2022; Gieshoff, Schuler \& Jahany 2024). Derartige Studien sind zudem nützlich, um zusätzliche Technologien als Unterstützung zu testen, wie es in der Studie von Gieshoff et al. (2024) der Fall war, die AR-Brillen testeten.
\end{styleStandard}

\begin{styleStandard}
Wie bereits angemerkt (§ \ref{bkm:Ref185868026}), spielt auch die Systemleistung eine wichtige Rolle im Umgang mit CAI-Tools. Die bisher durchgeführten Studien weisen auf zufriedenstellende Leistungen von CAI-Tools hin. ASE scheint bereits als unterstützende Technologie einsetzbar zu sein. Die Leistung von ASE-Systemen ist hoch, mit niedrigem Word Error Rate (z. B. 5.04\% in Fantinuoli 2017b) bzw. hohe Präzision (81.43\% in Pisani \& Fantinuoli 2021) des Transkripts. Bessere Leistungen werden nach Fine-Tuning mit einer domänenspezifischen Terminologieliste erreicht (Rodríguez et al. 2021). Die Leistung der ASE von Zahlen und Fachtermini ist im Durchschnitt bereits sehr hoch: Sie erreichte F1-Werte von 1 (Zahlen) und 0.97 (Fachtermini) in einem Experiment von Fantinuoli (2017b); Defrancq und Fantinuoli (2020) berichten von einer durchschnittlichen Präzision von 96\% für Zahlen. Auch die Latenz scheint kurz genug zu sein, um innerhalb des \textit{Ear-Voice-Spans} der DolmetscherInnen zu liegen. Systeme, die Glossare durch Terminologieextraktion und MÜ automatisch erstellen (wie KUDO Interpreter Assist) scheinen ebenfalls gute Ergebnisse zu liefern. In der Studie von Fantinuoli et al. (2022) wurden nur 1,5\% der automatisch extrahierten Termini als fehlerhaft eingestuft, während die MÜ-Qualität sehr gut bewertet wurde (91.2\% für Englisch {\textgreater} Französisch, 89.4\% für Englisch {\textgreater} Italienisch).
\end{styleStandard}

\begin{styleStandard}
Diese Ergebnisse sollten kritisch betrachtet werden. In den meisten Studien wurde Englisch als Ausgangssprache analysiert, während die Systemleistung für andere Sprache deutlich niedriger sein könnte. Darüber hinaus wurden die meisten Tests unter kontrollierten Bedingungen durchgeführt. Die Systemleistung kann von zahlreichen Faktoren beeinflusst werden, wie etwa die Sprechereigenschaften, die Tonqualität oder die Domäne, wofür Fachterminologie automatisch extrahiert werden soll.
\end{styleStandard}

\section[Fazit]{Fazit}
\label{bkm:Ref181546783}\begin{styleStandard}
Dieser Beitrag bietet eine umfangreiche Übersicht über den aktuellen Stand der Automation und Forschung im Bereich des computergestützten Dolmetschens an. Im ersten Teil des Kapitels wurden die Möglichkeiten der Automation der verschiedenen Dolmetschphasen erläutert und die relevanten Tools zusammenfassend präsentiert. Mit dem Ziel, Lesenden eine Orientierungshilfe für die Forschung, Lehre und Praxis zur Verfügung zu stellen, wurde außerdem einen Überblick über aktuelle Forschungsfragen, -methoden und -ergebnisse im Bereich des computergestützten Dolmetschens gegeben.
\end{styleStandard}

\begin{styleStandard}
Trotz der vielversprechenden Forschungsergebnisse gibt es noch viele Fragen, die die Forschung in Bezug auf die Auswirkungen des Einsatzes von CAI- Tools erörtern sollte. Sie betreffen in erster Linie die vielen Facetten der Interaktion zwischen DolmetscherInnen und ihren Tools; die Frage, wie diese Tools aussehen sollten, um eine breitere Implementierung in die Arbeitsabläufe der DolmetscherInnen zu fördern und den kognitiven Trade- Off, der mit der Tool-Nutzung verbunden ist, zu optimieren; sowie die Frage, wie die Ausbildung angepasst werden sollte, um die effektive Nutzung solcher Lösungen zu gewährleisten.
\end{styleStandard}

\begin{styleStandard}
Da CAI-Systeme offenbar bereits zufriedenstellende technische Leistungen bieten, könnten künftige Forschungsarbeiten die Erprobung solcher Systeme unter echten Arbeitsbedingungen in Betracht ziehen, mit dem Ziel, die Faktoren zu erforschen, die das computergestützte Dolmetschen beeinflussen und den Umfang der Untersuchungen über die traditionellen Sprachpaare und experimentelle Bedingungen hinaus zu erweitern.
\end{styleStandard}

\begin{styleStandard}
Schließlich ist zu erwarten, dass die beeindruckenden Fortschritte im Bereich der generativen KI und das Versprechen großer Sprachmodelle, die Leistung von CAI-Tools zu verbessern, weitere Forschungsarbeit über das Potenzial der Technologie zur Unterstützung von DolmetscherInnen in ihrem äußerst anspruchsvollen Beruf anregen werden.
\end{styleStandard}

\clearpage\setcounter{page}{1}\section[Referenzen]{Referenzen}
\begin{styleBibliography}
Biagini, Giulio. 2015. \textit{Glossario cartaceo e glossario elettronico durante l’interpretazione}. Trieste: Università di Trieste MA thesis.
\end{styleBibliography}

\begin{styleBibliography}
Bowker, Lynne. 2022. Computer-assisted translation and interpreting tools. In Federico Zanettin \& Christopher Rundle (eds.), \textit{The Routledge Handbook of Translation and Methodology}, 392–409. Oxon/New York: Routledge.
\end{styleBibliography}

\begin{styleBibliography}
Braun, Sabine. 2020. Technology and interpreting. In Minako O’Hagan (ed.), \textit{The Routledge Handbook of Translation and Technology}, 271–288. London: Routledge.
\end{styleBibliography}

\begin{styleBibliography}
Brezina, Vaclav \& W Platt. 2024. \#LancsBox X. Lancaster University. http://lancsbox.lancs.ac.uk.
\end{styleBibliography}

\begin{styleBibliography}
Chen, Sijia. 2020. The process of note-taking in consecutive interpreting: A digital pen recording approach. \textit{Interpreting. International Journal of Research and Practice in Interpreting} 22(1). 117–139. https://doi.org/10.1075/intp.00036.che.
\end{styleBibliography}

\begin{styleBibliography}
Chen, Sijia \& Jan-Louis Kruger. 2023. The effectiveness of computer-assisted interpreting: A preliminary study based on English-Chinese consecutive interpreting. \textit{Translation and Interpreting Studies} 18(3). 399–420. https://doi.org/10.1075/tis.21036.che.
\end{styleBibliography}

\begin{styleBibliography}
Chen, Sijia \& Jan-Louis Kruger. 2024a. A computer-assisted consecutive interpreting workflow: Training and evaluation. \textit{The Interpreter and Translator Trainer} 18(3). 380–399. https://doi.org/10.1080/1750399x.2024.2373553.
\end{styleBibliography}

\begin{styleBibliography}
Chen, Sijia \& Jan-Louis Kruger. 2024b. Visual processing during computer-assisted consecutive interpreting: Evidence from eye movements. \textit{Interpreting. International Journal of Research and Practice in Interpreting} 1–22. https://doi.org/10.1075/intp.00104.che.
\end{styleBibliography}

\begin{styleBibliography}
Defrancq, Bart \& Claudio Fantinuoli. 2020. Automatic Speech Recognition in the booth: Assessment of system performance, interpreters’ performances and interactions in the context of numbers. \textit{Target} 33(1). 73–102. https://doi.org/10.1075/target.19166.def.
\end{styleBibliography}

\begin{styleBibliography}
Defrancq, Bart, Helena Snoeck \& Claudio Fantinuoli. 2024. Interpreters’ performances and cognitive load in the context of a CAI tool. In Sharon Deane-Cox, Ursula Böser \& Marion Winters (eds.), \textit{Translation, interpreting and technological change: Innovations in research, practice and training} (Bloomsbury Advances in Translation), 38–58. London: Bloomsbury Academic.
\end{styleBibliography}

\begin{styleBibliography}
Desmet, Bart, Mieke Vandierendonck \& Bart Defrancq. 2018. Simultaneous interpretation of numbers and the impact of technological support. In Claudio Fantinuoli (ed.), \textit{Interpreting and technology}, 13–27. Berlin: Language Science Press. 10.5281/zenodo.1493291.
\end{styleBibliography}

\begin{styleBibliography}
Fantinuoli, Claudio. 2016. InterpretBank. Redefining computer-assisted interpreting tools. In João Esteves-Ferreira, Juliet Macan, Ruslan Mitkov \& Olaf-Michael Stefanov (eds.), \textit{Proceedings of 38th Conference Translating and the Computer}, 42–52. Geneva: Editions Tradulex. https://www.tradulex.com/varia/TC38-london2016.pdf. (11 October, 2024).
\end{styleBibliography}

\begin{styleBibliography}
Fantinuoli, Claudio. 2017a. Computerlinguistik in der Dolmetschpraxis unter besonderer Berücksichtigung der Korpusanalyse. In Silvia Hansen-Schirra, Stella Neumann \& Oliver Czulo (eds.), \textit{Annotation, exploitation and evaluation of parallel corpora}, 111–146. Berlin: Language Science Press. https://doi.org/10.5281/ZENODO.283501.
\end{styleBibliography}

\begin{styleBibliography}
Fantinuoli, Claudio. 2017b. Speech recognition in the interpreter workstation. In João Esteves-Ferreira, Juliet Macan, Ruslan Mitkov \& Olaf-Michael Stefanov (eds.), \textit{Proceedings of the 39th Conference Translating and the Computer}, 25–34. London: Editions Tradulex. https://www.asling.org/tc39/wp-content/uploads/TC39-proceedings-final-1Nov-4.20pm.pdf. (7 October, 2024).
\end{styleBibliography}

\begin{styleBibliography}
Fantinuoli, Claudio. 2018. Computer-assisted Interpreting: Challenges and Future Perspectives. In Gloria Corpas Pastor \& Isabel Durán-Muñoz (eds.), \textit{Trends in E-Tools and Resources for Translators and Interpreters}, 153–174. Leiden: Brill. https://doi.org/10.1163/9789004351790\_009.
\end{styleBibliography}

\begin{styleBibliography}
Fantinuoli, Claudio, Giulia Marchesini, David Landan \& Lukas Horak. 2022. KUDO Interpreter Assist: Automated Real-time Support for Remote Interpretation. In Ruslan Mitkov, Juliet Macan, João Esteves-Ferreira, Olaf-Michael Stefanov, Maria Recort Ruiz, David Chambers \& Vilelmini Sosoni (eds.), \textit{Proceedings of the 43rd Conference Translating and the Computer}, 68–77. Geneva: Editions Tradulex.
\end{styleBibliography}

\begin{styleBibliography}
Fantinuoli, Claudio \& Maddalena Montecchio. 2023. Defining maximum acceptable latency of AI-enhanced CAI tools. In Óscar Ferreiro Vázquez, Ana Correia \& Sílvia Araújo (eds.), \textit{Technological innovation put to the service of language learning, translation and interpreting: Insights from academic and professional contexts} (Lengua, Literatura, Traducción), vol. 2, 213–225. Berlin: Peter Lang. (15 April, 2022).
\end{styleBibliography}

\begin{styleBibliography}
Frittella, Francesca Maria. 2022. ASR-CAI tool-supported SI of numbers: Sit back, relax and enjoy interpreting? In Juliet Macan, Ruslan Mitkov, David Chambers, Olaf-Michael Stefanov, João Esteves-Ferreira, Maria Recort Ruiz \& Vilelmini Sosoni (eds.), \textit{Proceedings of the 43rd Conference Translating and the Computer}, 88–102. Geneva: Editions Tradulex.
\end{styleBibliography}

\begin{styleBibliography}
Frittella, Francesca Maria. 2023. \textit{Usability research for interpreter-centred technology: The case study of SmarTerp.} (Translation and Multilingual Natural Language Processing 21). Berlin: Language Science Press. 10.5281/zenodo.7376351.
\end{styleBibliography}

\begin{styleBibliography}
Frittella, Francesca Maria. 2024. \textit{Computer-assisted interpreting: Cognitive task analysis and evidence-informed instructional design recommendations}. University of Surrey Doctoral thesis.
\end{styleBibliography}

\begin{styleBibliography}
Gieshoff, Anne Catherine, Martin Schuler \& Zaniyar Jahany. 2024. The augmented interpreter: An exploratory study of the usability of augmented reality technology in interpreting. \textit{Interpreting}. https://doi.org/10.1075/intp.00108.gie.
\end{styleBibliography}

\begin{styleBibliography}
Gile, Daniel. 2009. \textit{Basic concepts and models for interpreter and translator training} (Benjamins Translation Library). Amsterdam: John Benjamins Publishing Company. https://doi.org/10.1075/btl.8.
\end{styleBibliography}

\begin{styleBibliography}
Han, Chao. 2018. Latent trait modelling of rater accuracy in formative peer assessment of English-Chinese consecutive interpreting. \textit{Assessment \& Evaluation in Higher Education} 43(6). 979–994. https://doi.org/10.1080/02602938.2018.1424799.
\end{styleBibliography}

\begin{styleBibliography}
Hansen-Schirra, Silvia. 2012. Nutzbarkeit von Sprachtechnologien für die Translation. \textit{Trans-kom: Journal of Translation and Technical Communication Research} 5(2). 211–226. http://www.trans-kom.eu/bd05nr02/trans-kom\_05\_02\_02\_Hansen-Schirra\_Sprachtechnologien.20121219.pdf. (24 August, 2022).
\end{styleBibliography}

\begin{styleBibliography}
Hart, Sandra G. 2006. Nasa-Task Load Index (NASA-TLX); 20 Years Later. \textit{Proceedings of the Human Factors and Ergonomics Society Annual Meeting} 50(9). 904–908. https://doi.org/10.1177/154193120605000909.
\end{styleBibliography}

\begin{styleBibliography}
Kalina, Sylvia. 2005. Quality Assurance for Interpreting Processes. \textit{Meta: Translators’ Journal} 50(2). 768–784. https://doi.org/10.7202/011017ar.
\end{styleBibliography}

\begin{styleBibliography}
Kilgarriff, Adam, Vít Baisa, Jan Bušta, Miloš Jakubíček, Vojtěch Kovář, Jan Michelfeit, Pavel Rychlý \& Vít Suchomel. 2014. The Sketch Engine: Ten years on. \textit{Lexicography} 1(1). 7–36. https://doi.org/10.1007/s40607-014-0009-9.
\end{styleBibliography}

\begin{styleBibliography}
Laugwitz, Bettina, Theo Held \& Martin Schrepp. 2008. Construction and Evaluation of a User Experience Questionnaire. In Andreas Holzinger (ed.), \textit{HCI and Usability for Education and Work} (Lecture Notes in Computer Science), vol. 5298, 63–76. Berlin, Heidelberg: Springer Berlin Heidelberg. https://doi.org/10.1007/978-3-540-89350-9\_6.
\end{styleBibliography}

\begin{styleBibliography}
Li, Tianyun \& Agnieszka Chmiel. 2024. Automatic subtitles increase accuracy and decrease cognitive load in simultaneous interpreting. \textit{Interpreting}. John Benjamins 26(2). 253–281. https://doi.org/10.1075/intp.00111.li.
\end{styleBibliography}

\begin{styleBibliography}
Orlando, Marc. 2014. A study on the amenability of digital \ pen technology in a hybrid mode of interpreting: Consec-simul with notes. \textit{Translation \& Interpreting} 6(2). 39–54. https://doi.org/10.12807/ti.106202.2014.a03.
\end{styleBibliography}

\begin{styleBibliography}
Parasuraman, Raja, Thomas B. Sheridan \& Christopher .D. Wickens. 2000. A model for types and levels of human interaction with automation. \textit{IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans} 30(3). 286–297. https://doi.org/10.1109/3468.844354.
\end{styleBibliography}

\begin{styleBibliography}
Pisani, Elisabetta \& Claudio Fantinuoli. 2021. Measuring the impact of automatic speech recognition on number rendition in simultaneous interpreting. In Caiwen Wang \& Binghan Zheng (eds.), \textit{Empirical Studies of Translation and Interpreting: The Post-Structuralist Approach}, 181–197. New York: Routledge. https://doi.org/10.4324/9781003017400.
\end{styleBibliography}

\begin{styleBibliography}
Pöchhacker, Franz \& Minhua Liu. 2024. Interpreting technologized: Distance and assistance. \textit{Interpreting. International Journal of Research and Practice in Interpreting} 26(2). 157–177. https://doi.org/10.1075/intp.00112.poc.
\end{styleBibliography}

\begin{styleBibliography}
Prandi, Bianca. 2015. The use of CAI tools in interpreters’ training: A pilot study. In João Esteves-Ferreira, Juliet Macan, Ruslan Mitkov \& Olaf-Michael Stefanov (eds.), \textit{Proceedings of the 37th Conference Translating and the Computer}, 48–57. London: AsLing. https://aclanthology.org/2015.tc-1.8.
\end{styleBibliography}

\begin{styleBibliography}
Prandi, Bianca. 2018. An exploratory study on CAI tools in Simultaneous Interpreting: Theoretical framework and stimulus validation. In Claudio Fantinuoli (ed.), \textit{Interpreting and technology} (Translation and Multilingual Natural Language Processing 11), 29–59. Berlin: Language Science Press. http://langsci-press.org/catalog/book/209.
\end{styleBibliography}

\begin{styleBibliography}
Prandi, Bianca. 2023. \textit{Computer-assisted simultaneous interpreting: A cognitive-experimental study on terminology} (Translation and Multilingual Natural Language Processing 22). Berlin: Language Science Press. https://doi.org/10.5281/zenodo.7143056.
\end{styleBibliography}

\begin{styleBibliography}
Prandi, Bianca. 2025. Computer-Assisted Interpreting (CAI) Tools and CAI Tool Training. In Elena Davitti, Sabine Braun \& Tomasz Korybski (eds.), \textit{Routledge Handbook of Interpreting and Technology}. London: Routledge.
\end{styleBibliography}

\begin{styleBibliography}
Pym, Anthony \& Yu Hao. 2024. What are language technologies and why should we know about them? In Anthony Pym \& Yu Hao (eds.), \textit{How to augment language skills: Generative AI and machine translation in language learning and translator training}, 1–31. 1st edn. London: Routledge. https://doi.org/10.4324/9781032648033.
\end{styleBibliography}

\begin{styleBibliography}
Rodríguez González, Eloy, Muhammad Ahmed Saeed, Tomasz Korybski, Elena Davitti \& Sabine Braun. 2023. Reimagining the remote simultaneous interpreting interface to improve support for interpreters. In Oscar Ferreiro Vázquez, Ana Teresa Vara \& Silvia Lima Gonçalves Araújo (eds.), \textit{Technological innovation for language learning, translation and interpreting}, 227–246. Berlin: Peter Lang.
\end{styleBibliography}

\begin{styleBibliography}
Rodríguez, Susana, Roberto Gretter, Marco Matassoni, Daniele Falavigna, Álvaro Alonso, Oscar Corcho \& Mariano Rico. 2021. SmarTerp: A CAI system to support simultaneous interpreters in real-time. In Ruslan Mitkov, Vilelmini Sosoni, Julie Christine Giguère, Elena Murgolo \& Elizabeth Deysel (eds.), \textit{Proceedings of the Translation and Interpreting Technology Online Conference}, 102–109. Online: INCOMA Ltd. https://doi.org/10.26615/978-954-452-071-7\_012.
\end{styleBibliography}

\begin{styleBibliography}
Rütten, Anja. 2007. \textit{Informations- und Wissensmanagement im Konferenzdolmetschen} (Sabest. Saarbrücker Beiträge Zur Sprach- Und Translationswissenschaft). Vol. 15. Berlin: Peter Lang. https://www.peterlang.com/document/1103583. (7 October, 2024).
\end{styleBibliography}

\begin{styleBibliography}
Saeed, Muhammad Ahmed, Eloy Rodríguez González, Tomasz Korybski, Elena Davitti \& Sabine Braun. 2022. Connected yet distant: An experimental study into the visual needs of the interpreter in remote simultaneous interpreting. In Masaaki Kurosu (ed.), \textit{Human-computer interaction. User experience and behavior} (Lecture Notes in Computer Science), vol. 13304, 214–232. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-031-05412-9\_16.
\end{styleBibliography}

\begin{styleBibliography}
Seeber, Kilian G. 2013. Cognitive load in simultaneous interpreting: Measures and methods. \textit{Target. International Journal of Translation Studies} 25(1). 18–32. https://doi.org/10.1075/target.25.1.03see.
\end{styleBibliography}

\begin{styleBibliography}
Shao, Zhangminzi \& Bart Defrancq. 2024. Fundamental frequency as an acoustic mirror of interpreters’ cognitive states. \textit{Interpreting. International Journal of Research and Practice in Interpreting}. https://doi.org/10.1075/intp.00107.sha.
\end{styleBibliography}

\begin{styleBibliography}
Stoll, Christoph. 2009. \textit{Jenseits simultanfähiger Terminologiesysteme: Methoden der Vorverlagerung und Fixierung von Kognition im Arbeitsablauf professioneller Konferenzdolmetscher} (Heidelberger Studien Zur Übersetzungswissenschaft 13). Trier: WVT, Wissenschaftlicher Verlag Trier.
\end{styleBibliography}

\begin{styleBibliography}
Ünlü, Cihan. 2023a. \textit{Automatic speech recognition in consecutive interpreter workstation: Computer-aided interpreting tool “Sight-Terp” / Otomatik konuşma tanıma sistemlerinin ardıl çeviride kullanılması: Sight-Terp}. Ankara: Hacettepe Üniversitesi MA thesis.
\end{styleBibliography}

\begin{styleBibliography}
Ünlü, Cihan. 2023b. InterpreTutor: Using large language models for interpreter assessment. In Constantin Orasan, Ruslan Mitkov, Gloria Corpas Pastor \& Johanna Monti (eds.), \textit{International Conference on Human-Informed Translation and Interpreting Technology (HiT-IT 2023)}, 78–96. Naples: INCOMA Ltd. https://doi.org/10.26615/issn.2683-0078.2023\_007.
\end{styleBibliography}

\begin{styleBibliography}
Van Cauwenberghe, Goran. 2020. \textit{Étude expérimentale de l’impact d’un soutien visuel automatisé sur la restitution de terminologie spécialisée}. Ghent: Universiteit Ghent MA thesis.
\end{styleBibliography}

\begin{styleBibliography}
Wang, Xinyu \& Caiwen Wang. 2019. Can Computer-assisted Interpreting Tools Assist Interpreting? \textit{Transletters. International Journal of Translation and Interpreting} 3. 109–139. https://www.uco.es/ucopress/ojs/index.php/tl/article/view/11575.
\end{styleBibliography}

\begin{styleBibliography}
Will, Martin. 2020. Computer aided interpreting (CAI) for conference interpreters. Concepts, content and prospects. \textit{ESSACHESS-Journal for Communication Studies} 13(25). 37–71. https://www.essachess.com/index.php/jcs/article/view/480. (7 October, 2024).
\end{styleBibliography}

\begin{styleBibliography}
Xu, Ran. 2018. Corpus-based terminological preparation for simultaneous interpreting. \textit{Interpreting} 20(1). 29–58. https://doi.org/10.1075/intp.00002.xu.
\end{styleBibliography}

\begin{styleBibliography}
Xu, Ran \& Serge Sharoff. 2014. Evaluating term extraction methods for interpreters. In Patrick Drouin, Natalia Grabar, Thierry Hamon \& Kyo Kageura (eds.), \textit{Proceedings of the 4th International Workshop on Computational Terminology (Computerm)}, 86–93. Dublin: Association for Computational Linguistics and Dublin City University. https://doi.org/10.3115/v1/w14-4811.
\end{styleBibliography}

\begin{styleBibliography}
Yuan, Lu \& Binhua Wang. 2023. Cognitive processing of the extra visual layer of live captioning in simultaneous interpreting. Triangulation of eye-tracked process and performance data. \textit{Ampersand} 11. 100131. https://doi.org/10/gsc8x8.
\end{styleBibliography}

\end{document}
